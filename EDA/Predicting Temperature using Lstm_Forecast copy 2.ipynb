{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bcfho8jZh2sD"
      },
      "source": [
        "### Time Series Forecasting using LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "OabeeefPilgR"
      },
      "outputs": [],
      "source": [
        "# Importing libraries\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from convert_columns_to_floats import *\n",
        "\n",
        "mpl.rcParams['figure.figsize'] = (8,6)\n",
        "mpl.rcParams['axes.grid'] = False\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Memory Reducer\n",
        "# :df pandas dataframe to reduce size             # type: pd.DataFrame()\n",
        "# :verbose                                        # type: bool\n",
        "def reduce_mem_usage(df, verbose=True):\n",
        "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
        "    start_mem = df.memory_usage().sum() / 1024**2\n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtypes\n",
        "        if col_type in numerics:\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "            if str(col_type)[:3] == 'int':\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)\n",
        "            else:\n",
        "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                    df[col] = df[col].astype(np.float16)\n",
        "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64)\n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Size of the dataset: (5292, 16) \n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>timestamp</th>\n",
              "      <th>temperature</th>\n",
              "      <th>humidity</th>\n",
              "      <th>pressure_msl</th>\n",
              "      <th>pressure_surface</th>\n",
              "      <th>global_irradiance</th>\n",
              "      <th>direct_irradiance</th>\n",
              "      <th>diffuse_irradiance</th>\n",
              "      <th>cloud_cover</th>\n",
              "      <th>wind_speed</th>\n",
              "      <th>wind_direction</th>\n",
              "      <th>precipitation</th>\n",
              "      <th>rain</th>\n",
              "      <th>showers</th>\n",
              "      <th>snowfall</th>\n",
              "      <th>weather_code</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2022-07-11 12:00:00</td>\n",
              "      <td>[22.0, 22.6, 23.1, 23.4, 23.2, 22.7, 21.6, 20....</td>\n",
              "      <td>[42.0, 42.0, 41.0, 39.0, 40.0, 41.0, 49.0, 58....</td>\n",
              "      <td>[1021.5, 1021.0, 1020.6, 1020.2, 1019.7, 1019....</td>\n",
              "      <td>[1007.9, 1007.4, 1007.1, 1006.7, 1006.2, 1006....</td>\n",
              "      <td>[599.0, 645.0, 546.0, 507.0, 393.0, 245.0, 88....</td>\n",
              "      <td>[271.9, 390.3, 333.4, 422.8, 450.5, 389.1, 127...</td>\n",
              "      <td>[352.0, 307.0, 285.0, 226.0, 159.0, 106.0, 64....</td>\n",
              "      <td>[67.0, 80.0, 68.0, 54.0, 57.0, 90.0, 100.0, 10...</td>\n",
              "      <td>[6.2, 6.0, 5.8, 6.2, 6.6, 6.6, 3.2, 1.5, 4.0, ...</td>\n",
              "      <td>[173.0, 147.0, 150.0, 159.0, 158.0, 167.0, 153...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2022-07-11 13:00:00</td>\n",
              "      <td>[22.6, 23.1, 23.4, 23.2, 22.7, 21.6, 20.3, 18....</td>\n",
              "      <td>[42.0, 41.0, 39.0, 40.0, 41.0, 49.0, 58.0, 64....</td>\n",
              "      <td>[1021.0, 1020.6, 1020.2, 1019.7, 1019.8, 1020....</td>\n",
              "      <td>[1007.4, 1007.1, 1006.7, 1006.2, 1006.2, 1006....</td>\n",
              "      <td>[645.0, 546.0, 507.0, 393.0, 245.0, 88.0, 10.0...</td>\n",
              "      <td>[390.3, 333.4, 422.8, 450.5, 389.1, 127.0, 0.0...</td>\n",
              "      <td>[307.0, 285.0, 226.0, 159.0, 106.0, 64.0, 10.0...</td>\n",
              "      <td>[80.0, 68.0, 54.0, 57.0, 90.0, 100.0, 100.0, 1...</td>\n",
              "      <td>[6.0, 5.8, 6.2, 6.6, 6.6, 3.2, 1.5, 4.0, 2.9, ...</td>\n",
              "      <td>[147.0, 150.0, 159.0, 158.0, 167.0, 153.0, 104...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2022-07-11 14:00:00</td>\n",
              "      <td>[23.2, 23.6, 23.5, 23.0, 22.1, 20.4, 18.9, 18....</td>\n",
              "      <td>[38.0, 38.0, 38.0, 39.0, 46.0, 54.0, 63.0, 62....</td>\n",
              "      <td>[1020.6, 1020.3, 1019.6, 1019.6, 1020.0, 1020....</td>\n",
              "      <td>[1007.1, 1006.8, 1006.1, 1006.1, 1006.4, 1006....</td>\n",
              "      <td>[417.0, 442.0, 417.0, 267.0, 96.0, 11.0, 0.0, ...</td>\n",
              "      <td>[149.5, 287.4, 525.5, 481.5, 158.8, 0.0, 0.0, ...</td>\n",
              "      <td>[300.0, 251.0, 144.0, 95.0, 66.0, 11.0, 0.0, 0...</td>\n",
              "      <td>[86.0, 62.0, 24.0, 88.0, 100.0, 100.0, 100.0, ...</td>\n",
              "      <td>[4.0, 5.6, 6.8, 5.3, 4.5, 2.5, 2.9, 3.7, 1.3, ...</td>\n",
              "      <td>[170.0, 165.0, 155.0, 152.0, 166.0, 90.0, 7.0,...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[3.0, 2.0, 1.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2022-07-11 15:00:00</td>\n",
              "      <td>[23.6, 23.5, 23.0, 22.1, 20.4, 18.9, 18.2, 18....</td>\n",
              "      <td>[38.0, 38.0, 39.0, 46.0, 54.0, 63.0, 62.0, 65....</td>\n",
              "      <td>[1020.3, 1019.6, 1019.6, 1020.0, 1020.5, 1021....</td>\n",
              "      <td>[1006.8, 1006.1, 1006.1, 1006.4, 1006.8, 1007....</td>\n",
              "      <td>[442.0, 417.0, 267.0, 96.0, 11.0, 0.0, 0.0, 0....</td>\n",
              "      <td>[287.4, 525.5, 481.5, 158.8, 0.0, 0.0, 0.0, 0....</td>\n",
              "      <td>[251.0, 144.0, 95.0, 66.0, 11.0, 0.0, 0.0, 0.0...</td>\n",
              "      <td>[62.0, 24.0, 88.0, 100.0, 100.0, 100.0, 92.0, ...</td>\n",
              "      <td>[5.6, 6.8, 5.3, 4.5, 2.5, 2.9, 3.7, 1.3, 2.1, ...</td>\n",
              "      <td>[165.0, 155.0, 152.0, 166.0, 90.0, 7.0, 11.0, ...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[2.0, 1.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2022-07-11 16:00:00</td>\n",
              "      <td>[23.5, 23.0, 22.1, 20.4, 18.9, 18.2, 18.0, 17....</td>\n",
              "      <td>[38.0, 39.0, 46.0, 54.0, 63.0, 62.0, 65.0, 65....</td>\n",
              "      <td>[1019.6, 1019.6, 1020.0, 1020.5, 1021.1, 1021....</td>\n",
              "      <td>[1006.1, 1006.1, 1006.4, 1006.8, 1007.4, 1007....</td>\n",
              "      <td>[417.0, 267.0, 96.0, 11.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
              "      <td>[525.5, 481.5, 158.8, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
              "      <td>[144.0, 95.0, 66.0, 11.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[24.0, 88.0, 100.0, 100.0, 100.0, 92.0, 90.0, ...</td>\n",
              "      <td>[6.8, 5.3, 4.5, 2.5, 2.9, 3.7, 1.3, 2.1, 3.1, ...</td>\n",
              "      <td>[155.0, 152.0, 166.0, 90.0, 7.0, 11.0, 146.0, ...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[1.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 2.0, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             timestamp                                        temperature  \\\n",
              "0  2022-07-11 12:00:00  [22.0, 22.6, 23.1, 23.4, 23.2, 22.7, 21.6, 20....   \n",
              "1  2022-07-11 13:00:00  [22.6, 23.1, 23.4, 23.2, 22.7, 21.6, 20.3, 18....   \n",
              "2  2022-07-11 14:00:00  [23.2, 23.6, 23.5, 23.0, 22.1, 20.4, 18.9, 18....   \n",
              "3  2022-07-11 15:00:00  [23.6, 23.5, 23.0, 22.1, 20.4, 18.9, 18.2, 18....   \n",
              "4  2022-07-11 16:00:00  [23.5, 23.0, 22.1, 20.4, 18.9, 18.2, 18.0, 17....   \n",
              "\n",
              "                                            humidity  \\\n",
              "0  [42.0, 42.0, 41.0, 39.0, 40.0, 41.0, 49.0, 58....   \n",
              "1  [42.0, 41.0, 39.0, 40.0, 41.0, 49.0, 58.0, 64....   \n",
              "2  [38.0, 38.0, 38.0, 39.0, 46.0, 54.0, 63.0, 62....   \n",
              "3  [38.0, 38.0, 39.0, 46.0, 54.0, 63.0, 62.0, 65....   \n",
              "4  [38.0, 39.0, 46.0, 54.0, 63.0, 62.0, 65.0, 65....   \n",
              "\n",
              "                                        pressure_msl  \\\n",
              "0  [1021.5, 1021.0, 1020.6, 1020.2, 1019.7, 1019....   \n",
              "1  [1021.0, 1020.6, 1020.2, 1019.7, 1019.8, 1020....   \n",
              "2  [1020.6, 1020.3, 1019.6, 1019.6, 1020.0, 1020....   \n",
              "3  [1020.3, 1019.6, 1019.6, 1020.0, 1020.5, 1021....   \n",
              "4  [1019.6, 1019.6, 1020.0, 1020.5, 1021.1, 1021....   \n",
              "\n",
              "                                    pressure_surface  \\\n",
              "0  [1007.9, 1007.4, 1007.1, 1006.7, 1006.2, 1006....   \n",
              "1  [1007.4, 1007.1, 1006.7, 1006.2, 1006.2, 1006....   \n",
              "2  [1007.1, 1006.8, 1006.1, 1006.1, 1006.4, 1006....   \n",
              "3  [1006.8, 1006.1, 1006.1, 1006.4, 1006.8, 1007....   \n",
              "4  [1006.1, 1006.1, 1006.4, 1006.8, 1007.4, 1007....   \n",
              "\n",
              "                                   global_irradiance  \\\n",
              "0  [599.0, 645.0, 546.0, 507.0, 393.0, 245.0, 88....   \n",
              "1  [645.0, 546.0, 507.0, 393.0, 245.0, 88.0, 10.0...   \n",
              "2  [417.0, 442.0, 417.0, 267.0, 96.0, 11.0, 0.0, ...   \n",
              "3  [442.0, 417.0, 267.0, 96.0, 11.0, 0.0, 0.0, 0....   \n",
              "4  [417.0, 267.0, 96.0, 11.0, 0.0, 0.0, 0.0, 0.0,...   \n",
              "\n",
              "                                   direct_irradiance  \\\n",
              "0  [271.9, 390.3, 333.4, 422.8, 450.5, 389.1, 127...   \n",
              "1  [390.3, 333.4, 422.8, 450.5, 389.1, 127.0, 0.0...   \n",
              "2  [149.5, 287.4, 525.5, 481.5, 158.8, 0.0, 0.0, ...   \n",
              "3  [287.4, 525.5, 481.5, 158.8, 0.0, 0.0, 0.0, 0....   \n",
              "4  [525.5, 481.5, 158.8, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
              "\n",
              "                                  diffuse_irradiance  \\\n",
              "0  [352.0, 307.0, 285.0, 226.0, 159.0, 106.0, 64....   \n",
              "1  [307.0, 285.0, 226.0, 159.0, 106.0, 64.0, 10.0...   \n",
              "2  [300.0, 251.0, 144.0, 95.0, 66.0, 11.0, 0.0, 0...   \n",
              "3  [251.0, 144.0, 95.0, 66.0, 11.0, 0.0, 0.0, 0.0...   \n",
              "4  [144.0, 95.0, 66.0, 11.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "\n",
              "                                         cloud_cover  \\\n",
              "0  [67.0, 80.0, 68.0, 54.0, 57.0, 90.0, 100.0, 10...   \n",
              "1  [80.0, 68.0, 54.0, 57.0, 90.0, 100.0, 100.0, 1...   \n",
              "2  [86.0, 62.0, 24.0, 88.0, 100.0, 100.0, 100.0, ...   \n",
              "3  [62.0, 24.0, 88.0, 100.0, 100.0, 100.0, 92.0, ...   \n",
              "4  [24.0, 88.0, 100.0, 100.0, 100.0, 92.0, 90.0, ...   \n",
              "\n",
              "                                          wind_speed  \\\n",
              "0  [6.2, 6.0, 5.8, 6.2, 6.6, 6.6, 3.2, 1.5, 4.0, ...   \n",
              "1  [6.0, 5.8, 6.2, 6.6, 6.6, 3.2, 1.5, 4.0, 2.9, ...   \n",
              "2  [4.0, 5.6, 6.8, 5.3, 4.5, 2.5, 2.9, 3.7, 1.3, ...   \n",
              "3  [5.6, 6.8, 5.3, 4.5, 2.5, 2.9, 3.7, 1.3, 2.1, ...   \n",
              "4  [6.8, 5.3, 4.5, 2.5, 2.9, 3.7, 1.3, 2.1, 3.1, ...   \n",
              "\n",
              "                                      wind_direction  \\\n",
              "0  [173.0, 147.0, 150.0, 159.0, 158.0, 167.0, 153...   \n",
              "1  [147.0, 150.0, 159.0, 158.0, 167.0, 153.0, 104...   \n",
              "2  [170.0, 165.0, 155.0, 152.0, 166.0, 90.0, 7.0,...   \n",
              "3  [165.0, 155.0, 152.0, 166.0, 90.0, 7.0, 11.0, ...   \n",
              "4  [155.0, 152.0, 166.0, 90.0, 7.0, 11.0, 146.0, ...   \n",
              "\n",
              "                                       precipitation  \\\n",
              "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "\n",
              "                                                rain  \\\n",
              "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "\n",
              "                                             showers  \\\n",
              "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "\n",
              "                                            snowfall  \\\n",
              "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "\n",
              "                                        weather_code  \n",
              "0  [2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, ...  \n",
              "1  [2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, ...  \n",
              "2  [3.0, 2.0, 1.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, ...  \n",
              "3  [2.0, 1.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, ...  \n",
              "4  [1.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 2.0, ...  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "orig_df = pd.read_csv('/Users/faymajidelhassan/Downloads/Master project /Data/Weather/forecasts/open_meteo.csv') \n",
        "df = orig_df.copy() \n",
        "print(f'Size of the dataset: {df.shape} \\n')  \n",
        "print() \n",
        "display(df.head(5))\n",
        "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
        "df.set_index('timestamp', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing column: temperature\n",
            "Processed column: temperature\n",
            "Processing column: humidity\n",
            "Processed column: humidity\n",
            "Processing column: pressure_msl\n",
            "Processed column: pressure_msl\n",
            "Processing column: pressure_surface\n",
            "Processed column: pressure_surface\n",
            "Processing column: global_irradiance\n",
            "Processed column: global_irradiance\n",
            "Processing column: direct_irradiance\n",
            "Processed column: direct_irradiance\n",
            "Processing column: diffuse_irradiance\n",
            "Processed column: diffuse_irradiance\n",
            "Processing column: cloud_cover\n",
            "Processed column: cloud_cover\n",
            "Processing column: wind_speed\n",
            "Processed column: wind_speed\n",
            "Processing column: wind_direction\n",
            "Processed column: wind_direction\n",
            "Processing column: precipitation\n",
            "Processed column: precipitation\n",
            "Processing column: rain\n",
            "Processed column: rain\n",
            "Processing column: showers\n",
            "Processed column: showers\n",
            "Processing column: snowfall\n",
            "Processed column: snowfall\n",
            "                     temperature  humidity  pressure_msl  pressure_surface  \\\n",
            "timestamp                                                                    \n",
            "2022-07-11 12:00:00          156       156           156               156   \n",
            "2022-07-11 13:00:00          155       155           155               155   \n",
            "2022-07-11 14:00:00          154       154           154               154   \n",
            "2022-07-11 15:00:00          153       153           153               153   \n",
            "2022-07-11 16:00:00          152       152           152               152   \n",
            "...                          ...       ...           ...               ...   \n",
            "2023-02-17 08:00:00          160       160           160               160   \n",
            "2023-02-17 09:00:00          159       159           159               159   \n",
            "2023-02-17 10:00:00          158       158           158               158   \n",
            "2023-02-17 11:00:00          157       157           157               157   \n",
            "2023-02-17 12:00:00          156       156           156               156   \n",
            "\n",
            "                     global_irradiance  direct_irradiance  diffuse_irradiance  \\\n",
            "timestamp                                                                       \n",
            "2022-07-11 12:00:00                156                156                 156   \n",
            "2022-07-11 13:00:00                155                155                 155   \n",
            "2022-07-11 14:00:00                154                154                 154   \n",
            "2022-07-11 15:00:00                153                153                 153   \n",
            "2022-07-11 16:00:00                152                152                 152   \n",
            "...                                ...                ...                 ...   \n",
            "2023-02-17 08:00:00                160                160                 160   \n",
            "2023-02-17 09:00:00                159                159                 159   \n",
            "2023-02-17 10:00:00                158                158                 158   \n",
            "2023-02-17 11:00:00                157                157                 157   \n",
            "2023-02-17 12:00:00                156                156                 156   \n",
            "\n",
            "                     cloud_cover  wind_speed  wind_direction  precipitation  \\\n",
            "timestamp                                                                     \n",
            "2022-07-11 12:00:00          156         156             156            156   \n",
            "2022-07-11 13:00:00          155         155             155            155   \n",
            "2022-07-11 14:00:00          154         154             154            154   \n",
            "2022-07-11 15:00:00          153         153             153            153   \n",
            "2022-07-11 16:00:00          152         152             152            152   \n",
            "...                          ...         ...             ...            ...   \n",
            "2023-02-17 08:00:00          160         160             160            160   \n",
            "2023-02-17 09:00:00          159         159             159            159   \n",
            "2023-02-17 10:00:00          158         158             158            158   \n",
            "2023-02-17 11:00:00          157         157             157            157   \n",
            "2023-02-17 12:00:00          156         156             156            156   \n",
            "\n",
            "                     rain  showers  snowfall  \n",
            "timestamp                                     \n",
            "2022-07-11 12:00:00   156      156       156  \n",
            "2022-07-11 13:00:00   155      155       155  \n",
            "2022-07-11 14:00:00   154      154       154  \n",
            "2022-07-11 15:00:00   153      153       153  \n",
            "2022-07-11 16:00:00   152      152       152  \n",
            "...                   ...      ...       ...  \n",
            "2023-02-17 08:00:00   160      160       160  \n",
            "2023-02-17 09:00:00   159      159       159  \n",
            "2023-02-17 10:00:00   158      158       158  \n",
            "2023-02-17 11:00:00   157      157       157  \n",
            "2023-02-17 12:00:00   156      156       156  \n",
            "\n",
            "[5292 rows x 14 columns]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>temperature</th>\n",
              "      <th>humidity</th>\n",
              "      <th>pressure_msl</th>\n",
              "      <th>pressure_surface</th>\n",
              "      <th>global_irradiance</th>\n",
              "      <th>direct_irradiance</th>\n",
              "      <th>diffuse_irradiance</th>\n",
              "      <th>cloud_cover</th>\n",
              "      <th>wind_speed</th>\n",
              "      <th>wind_direction</th>\n",
              "      <th>precipitation</th>\n",
              "      <th>rain</th>\n",
              "      <th>showers</th>\n",
              "      <th>snowfall</th>\n",
              "      <th>weather_code</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>timestamp</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2022-07-11 12:00:00</th>\n",
              "      <td>[22.0, 22.6, 23.1, 23.4, 23.2, 22.7, 21.6, 20....</td>\n",
              "      <td>[42.0, 42.0, 41.0, 39.0, 40.0, 41.0, 49.0, 58....</td>\n",
              "      <td>[1021.5, 1021.0, 1020.6, 1020.2, 1019.7, 1019....</td>\n",
              "      <td>[1007.9, 1007.4, 1007.1, 1006.7, 1006.2, 1006....</td>\n",
              "      <td>[599.0, 645.0, 546.0, 507.0, 393.0, 245.0, 88....</td>\n",
              "      <td>[271.9, 390.3, 333.4, 422.8, 450.5, 389.1, 127...</td>\n",
              "      <td>[352.0, 307.0, 285.0, 226.0, 159.0, 106.0, 64....</td>\n",
              "      <td>[67.0, 80.0, 68.0, 54.0, 57.0, 90.0, 100.0, 10...</td>\n",
              "      <td>[6.2, 6.0, 5.8, 6.2, 6.6, 6.6, 3.2, 1.5, 4.0, ...</td>\n",
              "      <td>[173.0, 147.0, 150.0, 159.0, 158.0, 167.0, 153...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-07-11 13:00:00</th>\n",
              "      <td>[22.6, 23.1, 23.4, 23.2, 22.7, 21.6, 20.3, 18....</td>\n",
              "      <td>[42.0, 41.0, 39.0, 40.0, 41.0, 49.0, 58.0, 64....</td>\n",
              "      <td>[1021.0, 1020.6, 1020.2, 1019.7, 1019.8, 1020....</td>\n",
              "      <td>[1007.4, 1007.1, 1006.7, 1006.2, 1006.2, 1006....</td>\n",
              "      <td>[645.0, 546.0, 507.0, 393.0, 245.0, 88.0, 10.0...</td>\n",
              "      <td>[390.3, 333.4, 422.8, 450.5, 389.1, 127.0, 0.0...</td>\n",
              "      <td>[307.0, 285.0, 226.0, 159.0, 106.0, 64.0, 10.0...</td>\n",
              "      <td>[80.0, 68.0, 54.0, 57.0, 90.0, 100.0, 100.0, 1...</td>\n",
              "      <td>[6.0, 5.8, 6.2, 6.6, 6.6, 3.2, 1.5, 4.0, 2.9, ...</td>\n",
              "      <td>[147.0, 150.0, 159.0, 158.0, 167.0, 153.0, 104...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-07-11 14:00:00</th>\n",
              "      <td>[23.2, 23.6, 23.5, 23.0, 22.1, 20.4, 18.9, 18....</td>\n",
              "      <td>[38.0, 38.0, 38.0, 39.0, 46.0, 54.0, 63.0, 62....</td>\n",
              "      <td>[1020.6, 1020.3, 1019.6, 1019.6, 1020.0, 1020....</td>\n",
              "      <td>[1007.1, 1006.8, 1006.1, 1006.1, 1006.4, 1006....</td>\n",
              "      <td>[417.0, 442.0, 417.0, 267.0, 96.0, 11.0, 0.0, ...</td>\n",
              "      <td>[149.5, 287.4, 525.5, 481.5, 158.8, 0.0, 0.0, ...</td>\n",
              "      <td>[300.0, 251.0, 144.0, 95.0, 66.0, 11.0, 0.0, 0...</td>\n",
              "      <td>[86.0, 62.0, 24.0, 88.0, 100.0, 100.0, 100.0, ...</td>\n",
              "      <td>[4.0, 5.6, 6.8, 5.3, 4.5, 2.5, 2.9, 3.7, 1.3, ...</td>\n",
              "      <td>[170.0, 165.0, 155.0, 152.0, 166.0, 90.0, 7.0,...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[3.0, 2.0, 1.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-07-11 15:00:00</th>\n",
              "      <td>[23.6, 23.5, 23.0, 22.1, 20.4, 18.9, 18.2, 18....</td>\n",
              "      <td>[38.0, 38.0, 39.0, 46.0, 54.0, 63.0, 62.0, 65....</td>\n",
              "      <td>[1020.3, 1019.6, 1019.6, 1020.0, 1020.5, 1021....</td>\n",
              "      <td>[1006.8, 1006.1, 1006.1, 1006.4, 1006.8, 1007....</td>\n",
              "      <td>[442.0, 417.0, 267.0, 96.0, 11.0, 0.0, 0.0, 0....</td>\n",
              "      <td>[287.4, 525.5, 481.5, 158.8, 0.0, 0.0, 0.0, 0....</td>\n",
              "      <td>[251.0, 144.0, 95.0, 66.0, 11.0, 0.0, 0.0, 0.0...</td>\n",
              "      <td>[62.0, 24.0, 88.0, 100.0, 100.0, 100.0, 92.0, ...</td>\n",
              "      <td>[5.6, 6.8, 5.3, 4.5, 2.5, 2.9, 3.7, 1.3, 2.1, ...</td>\n",
              "      <td>[165.0, 155.0, 152.0, 166.0, 90.0, 7.0, 11.0, ...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[2.0, 1.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-07-11 16:00:00</th>\n",
              "      <td>[23.5, 23.0, 22.1, 20.4, 18.9, 18.2, 18.0, 17....</td>\n",
              "      <td>[38.0, 39.0, 46.0, 54.0, 63.0, 62.0, 65.0, 65....</td>\n",
              "      <td>[1019.6, 1019.6, 1020.0, 1020.5, 1021.1, 1021....</td>\n",
              "      <td>[1006.1, 1006.1, 1006.4, 1006.8, 1007.4, 1007....</td>\n",
              "      <td>[417.0, 267.0, 96.0, 11.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
              "      <td>[525.5, 481.5, 158.8, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
              "      <td>[144.0, 95.0, 66.0, 11.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[24.0, 88.0, 100.0, 100.0, 100.0, 92.0, 90.0, ...</td>\n",
              "      <td>[6.8, 5.3, 4.5, 2.5, 2.9, 3.7, 1.3, 2.1, 3.1, ...</td>\n",
              "      <td>[155.0, 152.0, 166.0, 90.0, 7.0, 11.0, 146.0, ...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[1.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 2.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-02-17 08:00:00</th>\n",
              "      <td>[4.0, 7.3, 10.3, 12.4, 13.9, 14.9, 15.9, 15.6,...</td>\n",
              "      <td>[90.0, 75.0, 64.0, 58.0, 50.0, 48.0, 47.0, 48....</td>\n",
              "      <td>[1028.1, 1028.2, 1028.1, 1026.9, 1026.2, 1025....</td>\n",
              "      <td>[1013.5, 1013.8, 1013.8, 1012.8, 1012.1, 1011....</td>\n",
              "      <td>[170.0, 309.0, 415.0, 468.0, 491.0, 438.0, 337...</td>\n",
              "      <td>[258.1, 487.2, 617.8, 644.2, 673.1, 675.3, 573...</td>\n",
              "      <td>[76.0, 96.0, 112.0, 135.0, 119.0, 128.0, 126.0...</td>\n",
              "      <td>[0.0, 10.0, 0.0, 33.0, 100.0, 100.0, 0.0, 70.0...</td>\n",
              "      <td>[9.6, 10.1, 10.3, 10.5, 10.2, 10.0, 9.7, 11.8,...</td>\n",
              "      <td>[236.0, 235.0, 234.0, 239.0, 231.0, 240.0, 239...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[0, 1, 1, 2, 3, 3, 0, 2, 2, 3, 2, 2, 2, 2, 2, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-02-17 09:00:00</th>\n",
              "      <td>[7.3, 10.3, 12.4, 13.9, 14.9, 15.9, 15.6, 13.6...</td>\n",
              "      <td>[75.0, 64.0, 58.0, 50.0, 48.0, 47.0, 48.0, 54....</td>\n",
              "      <td>[1028.2, 1028.1, 1026.9, 1026.2, 1025.5, 1025....</td>\n",
              "      <td>[1013.8, 1013.8, 1012.8, 1012.1, 1011.5, 1011....</td>\n",
              "      <td>[309.0, 415.0, 468.0, 491.0, 438.0, 337.0, 220...</td>\n",
              "      <td>[487.2, 617.8, 644.2, 673.1, 675.3, 573.8, 493...</td>\n",
              "      <td>[96.0, 112.0, 135.0, 119.0, 128.0, 126.0, 87.0...</td>\n",
              "      <td>[10.0, 0.0, 33.0, 100.0, 100.0, 0.0, 70.0, 64....</td>\n",
              "      <td>[10.1, 10.3, 10.5, 10.2, 10.0, 9.7, 11.8, 10.0...</td>\n",
              "      <td>[235.0, 234.0, 239.0, 231.0, 240.0, 239.0, 239...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[1, 1, 2, 3, 3, 0, 2, 2, 3, 2, 2, 2, 2, 2, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-02-17 10:00:00</th>\n",
              "      <td>[10.3, 12.4, 13.9, 14.9, 15.9, 15.6, 13.6, 10....</td>\n",
              "      <td>[64.0, 58.0, 50.0, 48.0, 47.0, 48.0, 54.0, 67....</td>\n",
              "      <td>[1028.1, 1026.9, 1026.2, 1025.5, 1025.3, 1024....</td>\n",
              "      <td>[1013.8, 1012.8, 1012.1, 1011.5, 1011.4, 1010....</td>\n",
              "      <td>[415.0, 468.0, 491.0, 438.0, 337.0, 220.0, 79....</td>\n",
              "      <td>[617.8, 644.2, 673.1, 675.3, 573.8, 493.9, 331...</td>\n",
              "      <td>[112.0, 135.0, 119.0, 128.0, 126.0, 87.0, 51.0...</td>\n",
              "      <td>[0.0, 33.0, 100.0, 100.0, 0.0, 70.0, 64.0, 100...</td>\n",
              "      <td>[10.3, 10.5, 10.2, 10.0, 9.7, 11.8, 10.0, 7.1,...</td>\n",
              "      <td>[234.0, 239.0, 231.0, 240.0, 239.0, 239.0, 240...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[1, 2, 3, 3, 0, 2, 2, 3, 2, 2, 2, 2, 2, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-02-17 11:00:00</th>\n",
              "      <td>[13.0, 14.2, 15.1, 15.4, 15.5, 13.7, 11.0, 8.7...</td>\n",
              "      <td>[57.0, 51.0, 48.0, 50.0, 49.0, 55.0, 68.0, 78....</td>\n",
              "      <td>[1026.4, 1026.0, 1025.2, 1025.1, 1024.4, 1024....</td>\n",
              "      <td>[1012.3, 1012.0, 1011.2, 1011.1, 1010.4, 1010....</td>\n",
              "      <td>[437.0, 482.0, 444.0, 326.0, 215.0, 84.0, 3.0,...</td>\n",
              "      <td>[544.5, 571.3, 674.9, 579.0, 458.4, 357.9, 29....</td>\n",
              "      <td>[178.0, 134.0, 118.0, 127.0, 90.0, 45.0, 3.0, ...</td>\n",
              "      <td>[100.0, 0.0, 86.0, 99.0, 44.0, 37.0, 71.0, 69....</td>\n",
              "      <td>[10.8, 10.7, 9.9, 7.2, 8.9, 11.8, 7.6, 7.6, 9....</td>\n",
              "      <td>[244.0, 237.0, 251.0, 276.0, 249.0, 243.0, 239...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[3, 0, 2, 3, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-02-17 12:00:00</th>\n",
              "      <td>[14.2, 15.1, 15.4, 15.5, 13.7, 11.0, 8.7, 7.4,...</td>\n",
              "      <td>[51.0, 48.0, 50.0, 49.0, 55.0, 68.0, 78.0, 82....</td>\n",
              "      <td>[1026.0, 1025.2, 1025.1, 1024.4, 1024.6, 1025....</td>\n",
              "      <td>[1012.0, 1011.2, 1011.1, 1010.4, 1010.6, 1010....</td>\n",
              "      <td>[482.0, 444.0, 326.0, 215.0, 84.0, 3.0, 0.0, 0...</td>\n",
              "      <td>[571.3, 674.9, 579.0, 458.4, 357.9, 29.3, 0.0,...</td>\n",
              "      <td>[134.0, 118.0, 127.0, 90.0, 45.0, 3.0, 0.0, 0....</td>\n",
              "      <td>[0.0, 86.0, 99.0, 44.0, 37.0, 71.0, 69.0, 48.0...</td>\n",
              "      <td>[10.7, 9.9, 7.2, 8.9, 11.8, 7.6, 7.6, 9.0, 9.1...</td>\n",
              "      <td>[237.0, 251.0, 276.0, 249.0, 243.0, 239.0, 239...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[0, 2, 3, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 1, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5292 rows Ã— 15 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                           temperature  \\\n",
              "timestamp                                                                \n",
              "2022-07-11 12:00:00  [22.0, 22.6, 23.1, 23.4, 23.2, 22.7, 21.6, 20....   \n",
              "2022-07-11 13:00:00  [22.6, 23.1, 23.4, 23.2, 22.7, 21.6, 20.3, 18....   \n",
              "2022-07-11 14:00:00  [23.2, 23.6, 23.5, 23.0, 22.1, 20.4, 18.9, 18....   \n",
              "2022-07-11 15:00:00  [23.6, 23.5, 23.0, 22.1, 20.4, 18.9, 18.2, 18....   \n",
              "2022-07-11 16:00:00  [23.5, 23.0, 22.1, 20.4, 18.9, 18.2, 18.0, 17....   \n",
              "...                                                                ...   \n",
              "2023-02-17 08:00:00  [4.0, 7.3, 10.3, 12.4, 13.9, 14.9, 15.9, 15.6,...   \n",
              "2023-02-17 09:00:00  [7.3, 10.3, 12.4, 13.9, 14.9, 15.9, 15.6, 13.6...   \n",
              "2023-02-17 10:00:00  [10.3, 12.4, 13.9, 14.9, 15.9, 15.6, 13.6, 10....   \n",
              "2023-02-17 11:00:00  [13.0, 14.2, 15.1, 15.4, 15.5, 13.7, 11.0, 8.7...   \n",
              "2023-02-17 12:00:00  [14.2, 15.1, 15.4, 15.5, 13.7, 11.0, 8.7, 7.4,...   \n",
              "\n",
              "                                                              humidity  \\\n",
              "timestamp                                                                \n",
              "2022-07-11 12:00:00  [42.0, 42.0, 41.0, 39.0, 40.0, 41.0, 49.0, 58....   \n",
              "2022-07-11 13:00:00  [42.0, 41.0, 39.0, 40.0, 41.0, 49.0, 58.0, 64....   \n",
              "2022-07-11 14:00:00  [38.0, 38.0, 38.0, 39.0, 46.0, 54.0, 63.0, 62....   \n",
              "2022-07-11 15:00:00  [38.0, 38.0, 39.0, 46.0, 54.0, 63.0, 62.0, 65....   \n",
              "2022-07-11 16:00:00  [38.0, 39.0, 46.0, 54.0, 63.0, 62.0, 65.0, 65....   \n",
              "...                                                                ...   \n",
              "2023-02-17 08:00:00  [90.0, 75.0, 64.0, 58.0, 50.0, 48.0, 47.0, 48....   \n",
              "2023-02-17 09:00:00  [75.0, 64.0, 58.0, 50.0, 48.0, 47.0, 48.0, 54....   \n",
              "2023-02-17 10:00:00  [64.0, 58.0, 50.0, 48.0, 47.0, 48.0, 54.0, 67....   \n",
              "2023-02-17 11:00:00  [57.0, 51.0, 48.0, 50.0, 49.0, 55.0, 68.0, 78....   \n",
              "2023-02-17 12:00:00  [51.0, 48.0, 50.0, 49.0, 55.0, 68.0, 78.0, 82....   \n",
              "\n",
              "                                                          pressure_msl  \\\n",
              "timestamp                                                                \n",
              "2022-07-11 12:00:00  [1021.5, 1021.0, 1020.6, 1020.2, 1019.7, 1019....   \n",
              "2022-07-11 13:00:00  [1021.0, 1020.6, 1020.2, 1019.7, 1019.8, 1020....   \n",
              "2022-07-11 14:00:00  [1020.6, 1020.3, 1019.6, 1019.6, 1020.0, 1020....   \n",
              "2022-07-11 15:00:00  [1020.3, 1019.6, 1019.6, 1020.0, 1020.5, 1021....   \n",
              "2022-07-11 16:00:00  [1019.6, 1019.6, 1020.0, 1020.5, 1021.1, 1021....   \n",
              "...                                                                ...   \n",
              "2023-02-17 08:00:00  [1028.1, 1028.2, 1028.1, 1026.9, 1026.2, 1025....   \n",
              "2023-02-17 09:00:00  [1028.2, 1028.1, 1026.9, 1026.2, 1025.5, 1025....   \n",
              "2023-02-17 10:00:00  [1028.1, 1026.9, 1026.2, 1025.5, 1025.3, 1024....   \n",
              "2023-02-17 11:00:00  [1026.4, 1026.0, 1025.2, 1025.1, 1024.4, 1024....   \n",
              "2023-02-17 12:00:00  [1026.0, 1025.2, 1025.1, 1024.4, 1024.6, 1025....   \n",
              "\n",
              "                                                      pressure_surface  \\\n",
              "timestamp                                                                \n",
              "2022-07-11 12:00:00  [1007.9, 1007.4, 1007.1, 1006.7, 1006.2, 1006....   \n",
              "2022-07-11 13:00:00  [1007.4, 1007.1, 1006.7, 1006.2, 1006.2, 1006....   \n",
              "2022-07-11 14:00:00  [1007.1, 1006.8, 1006.1, 1006.1, 1006.4, 1006....   \n",
              "2022-07-11 15:00:00  [1006.8, 1006.1, 1006.1, 1006.4, 1006.8, 1007....   \n",
              "2022-07-11 16:00:00  [1006.1, 1006.1, 1006.4, 1006.8, 1007.4, 1007....   \n",
              "...                                                                ...   \n",
              "2023-02-17 08:00:00  [1013.5, 1013.8, 1013.8, 1012.8, 1012.1, 1011....   \n",
              "2023-02-17 09:00:00  [1013.8, 1013.8, 1012.8, 1012.1, 1011.5, 1011....   \n",
              "2023-02-17 10:00:00  [1013.8, 1012.8, 1012.1, 1011.5, 1011.4, 1010....   \n",
              "2023-02-17 11:00:00  [1012.3, 1012.0, 1011.2, 1011.1, 1010.4, 1010....   \n",
              "2023-02-17 12:00:00  [1012.0, 1011.2, 1011.1, 1010.4, 1010.6, 1010....   \n",
              "\n",
              "                                                     global_irradiance  \\\n",
              "timestamp                                                                \n",
              "2022-07-11 12:00:00  [599.0, 645.0, 546.0, 507.0, 393.0, 245.0, 88....   \n",
              "2022-07-11 13:00:00  [645.0, 546.0, 507.0, 393.0, 245.0, 88.0, 10.0...   \n",
              "2022-07-11 14:00:00  [417.0, 442.0, 417.0, 267.0, 96.0, 11.0, 0.0, ...   \n",
              "2022-07-11 15:00:00  [442.0, 417.0, 267.0, 96.0, 11.0, 0.0, 0.0, 0....   \n",
              "2022-07-11 16:00:00  [417.0, 267.0, 96.0, 11.0, 0.0, 0.0, 0.0, 0.0,...   \n",
              "...                                                                ...   \n",
              "2023-02-17 08:00:00  [170.0, 309.0, 415.0, 468.0, 491.0, 438.0, 337...   \n",
              "2023-02-17 09:00:00  [309.0, 415.0, 468.0, 491.0, 438.0, 337.0, 220...   \n",
              "2023-02-17 10:00:00  [415.0, 468.0, 491.0, 438.0, 337.0, 220.0, 79....   \n",
              "2023-02-17 11:00:00  [437.0, 482.0, 444.0, 326.0, 215.0, 84.0, 3.0,...   \n",
              "2023-02-17 12:00:00  [482.0, 444.0, 326.0, 215.0, 84.0, 3.0, 0.0, 0...   \n",
              "\n",
              "                                                     direct_irradiance  \\\n",
              "timestamp                                                                \n",
              "2022-07-11 12:00:00  [271.9, 390.3, 333.4, 422.8, 450.5, 389.1, 127...   \n",
              "2022-07-11 13:00:00  [390.3, 333.4, 422.8, 450.5, 389.1, 127.0, 0.0...   \n",
              "2022-07-11 14:00:00  [149.5, 287.4, 525.5, 481.5, 158.8, 0.0, 0.0, ...   \n",
              "2022-07-11 15:00:00  [287.4, 525.5, 481.5, 158.8, 0.0, 0.0, 0.0, 0....   \n",
              "2022-07-11 16:00:00  [525.5, 481.5, 158.8, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
              "...                                                                ...   \n",
              "2023-02-17 08:00:00  [258.1, 487.2, 617.8, 644.2, 673.1, 675.3, 573...   \n",
              "2023-02-17 09:00:00  [487.2, 617.8, 644.2, 673.1, 675.3, 573.8, 493...   \n",
              "2023-02-17 10:00:00  [617.8, 644.2, 673.1, 675.3, 573.8, 493.9, 331...   \n",
              "2023-02-17 11:00:00  [544.5, 571.3, 674.9, 579.0, 458.4, 357.9, 29....   \n",
              "2023-02-17 12:00:00  [571.3, 674.9, 579.0, 458.4, 357.9, 29.3, 0.0,...   \n",
              "\n",
              "                                                    diffuse_irradiance  \\\n",
              "timestamp                                                                \n",
              "2022-07-11 12:00:00  [352.0, 307.0, 285.0, 226.0, 159.0, 106.0, 64....   \n",
              "2022-07-11 13:00:00  [307.0, 285.0, 226.0, 159.0, 106.0, 64.0, 10.0...   \n",
              "2022-07-11 14:00:00  [300.0, 251.0, 144.0, 95.0, 66.0, 11.0, 0.0, 0...   \n",
              "2022-07-11 15:00:00  [251.0, 144.0, 95.0, 66.0, 11.0, 0.0, 0.0, 0.0...   \n",
              "2022-07-11 16:00:00  [144.0, 95.0, 66.0, 11.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "...                                                                ...   \n",
              "2023-02-17 08:00:00  [76.0, 96.0, 112.0, 135.0, 119.0, 128.0, 126.0...   \n",
              "2023-02-17 09:00:00  [96.0, 112.0, 135.0, 119.0, 128.0, 126.0, 87.0...   \n",
              "2023-02-17 10:00:00  [112.0, 135.0, 119.0, 128.0, 126.0, 87.0, 51.0...   \n",
              "2023-02-17 11:00:00  [178.0, 134.0, 118.0, 127.0, 90.0, 45.0, 3.0, ...   \n",
              "2023-02-17 12:00:00  [134.0, 118.0, 127.0, 90.0, 45.0, 3.0, 0.0, 0....   \n",
              "\n",
              "                                                           cloud_cover  \\\n",
              "timestamp                                                                \n",
              "2022-07-11 12:00:00  [67.0, 80.0, 68.0, 54.0, 57.0, 90.0, 100.0, 10...   \n",
              "2022-07-11 13:00:00  [80.0, 68.0, 54.0, 57.0, 90.0, 100.0, 100.0, 1...   \n",
              "2022-07-11 14:00:00  [86.0, 62.0, 24.0, 88.0, 100.0, 100.0, 100.0, ...   \n",
              "2022-07-11 15:00:00  [62.0, 24.0, 88.0, 100.0, 100.0, 100.0, 92.0, ...   \n",
              "2022-07-11 16:00:00  [24.0, 88.0, 100.0, 100.0, 100.0, 92.0, 90.0, ...   \n",
              "...                                                                ...   \n",
              "2023-02-17 08:00:00  [0.0, 10.0, 0.0, 33.0, 100.0, 100.0, 0.0, 70.0...   \n",
              "2023-02-17 09:00:00  [10.0, 0.0, 33.0, 100.0, 100.0, 0.0, 70.0, 64....   \n",
              "2023-02-17 10:00:00  [0.0, 33.0, 100.0, 100.0, 0.0, 70.0, 64.0, 100...   \n",
              "2023-02-17 11:00:00  [100.0, 0.0, 86.0, 99.0, 44.0, 37.0, 71.0, 69....   \n",
              "2023-02-17 12:00:00  [0.0, 86.0, 99.0, 44.0, 37.0, 71.0, 69.0, 48.0...   \n",
              "\n",
              "                                                            wind_speed  \\\n",
              "timestamp                                                                \n",
              "2022-07-11 12:00:00  [6.2, 6.0, 5.8, 6.2, 6.6, 6.6, 3.2, 1.5, 4.0, ...   \n",
              "2022-07-11 13:00:00  [6.0, 5.8, 6.2, 6.6, 6.6, 3.2, 1.5, 4.0, 2.9, ...   \n",
              "2022-07-11 14:00:00  [4.0, 5.6, 6.8, 5.3, 4.5, 2.5, 2.9, 3.7, 1.3, ...   \n",
              "2022-07-11 15:00:00  [5.6, 6.8, 5.3, 4.5, 2.5, 2.9, 3.7, 1.3, 2.1, ...   \n",
              "2022-07-11 16:00:00  [6.8, 5.3, 4.5, 2.5, 2.9, 3.7, 1.3, 2.1, 3.1, ...   \n",
              "...                                                                ...   \n",
              "2023-02-17 08:00:00  [9.6, 10.1, 10.3, 10.5, 10.2, 10.0, 9.7, 11.8,...   \n",
              "2023-02-17 09:00:00  [10.1, 10.3, 10.5, 10.2, 10.0, 9.7, 11.8, 10.0...   \n",
              "2023-02-17 10:00:00  [10.3, 10.5, 10.2, 10.0, 9.7, 11.8, 10.0, 7.1,...   \n",
              "2023-02-17 11:00:00  [10.8, 10.7, 9.9, 7.2, 8.9, 11.8, 7.6, 7.6, 9....   \n",
              "2023-02-17 12:00:00  [10.7, 9.9, 7.2, 8.9, 11.8, 7.6, 7.6, 9.0, 9.1...   \n",
              "\n",
              "                                                        wind_direction  \\\n",
              "timestamp                                                                \n",
              "2022-07-11 12:00:00  [173.0, 147.0, 150.0, 159.0, 158.0, 167.0, 153...   \n",
              "2022-07-11 13:00:00  [147.0, 150.0, 159.0, 158.0, 167.0, 153.0, 104...   \n",
              "2022-07-11 14:00:00  [170.0, 165.0, 155.0, 152.0, 166.0, 90.0, 7.0,...   \n",
              "2022-07-11 15:00:00  [165.0, 155.0, 152.0, 166.0, 90.0, 7.0, 11.0, ...   \n",
              "2022-07-11 16:00:00  [155.0, 152.0, 166.0, 90.0, 7.0, 11.0, 146.0, ...   \n",
              "...                                                                ...   \n",
              "2023-02-17 08:00:00  [236.0, 235.0, 234.0, 239.0, 231.0, 240.0, 239...   \n",
              "2023-02-17 09:00:00  [235.0, 234.0, 239.0, 231.0, 240.0, 239.0, 239...   \n",
              "2023-02-17 10:00:00  [234.0, 239.0, 231.0, 240.0, 239.0, 239.0, 240...   \n",
              "2023-02-17 11:00:00  [244.0, 237.0, 251.0, 276.0, 249.0, 243.0, 239...   \n",
              "2023-02-17 12:00:00  [237.0, 251.0, 276.0, 249.0, 243.0, 239.0, 239...   \n",
              "\n",
              "                                                         precipitation  \\\n",
              "timestamp                                                                \n",
              "2022-07-11 12:00:00  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "2022-07-11 13:00:00  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "2022-07-11 14:00:00  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "2022-07-11 15:00:00  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "2022-07-11 16:00:00  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "...                                                                ...   \n",
              "2023-02-17 08:00:00  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "2023-02-17 09:00:00  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "2023-02-17 10:00:00  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "2023-02-17 11:00:00  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "2023-02-17 12:00:00  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "\n",
              "                                                                  rain  \\\n",
              "timestamp                                                                \n",
              "2022-07-11 12:00:00  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "2022-07-11 13:00:00  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "2022-07-11 14:00:00  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "2022-07-11 15:00:00  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "2022-07-11 16:00:00  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "...                                                                ...   \n",
              "2023-02-17 08:00:00  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "2023-02-17 09:00:00  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "2023-02-17 10:00:00  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "2023-02-17 11:00:00  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "2023-02-17 12:00:00  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "\n",
              "                                                               showers  \\\n",
              "timestamp                                                                \n",
              "2022-07-11 12:00:00  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "2022-07-11 13:00:00  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "2022-07-11 14:00:00  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "2022-07-11 15:00:00  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "2022-07-11 16:00:00  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "...                                                                ...   \n",
              "2023-02-17 08:00:00  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "2023-02-17 09:00:00  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "2023-02-17 10:00:00  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "2023-02-17 11:00:00  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "2023-02-17 12:00:00  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "\n",
              "                                                              snowfall  \\\n",
              "timestamp                                                                \n",
              "2022-07-11 12:00:00  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "2022-07-11 13:00:00  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "2022-07-11 14:00:00  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "2022-07-11 15:00:00  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "2022-07-11 16:00:00  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "...                                                                ...   \n",
              "2023-02-17 08:00:00  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "2023-02-17 09:00:00  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "2023-02-17 10:00:00  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "2023-02-17 11:00:00  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "2023-02-17 12:00:00  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "\n",
              "                                                          weather_code  \n",
              "timestamp                                                               \n",
              "2022-07-11 12:00:00  [2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, ...  \n",
              "2022-07-11 13:00:00  [2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, ...  \n",
              "2022-07-11 14:00:00  [3.0, 2.0, 1.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, ...  \n",
              "2022-07-11 15:00:00  [2.0, 1.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, ...  \n",
              "2022-07-11 16:00:00  [1.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 2.0, ...  \n",
              "...                                                                ...  \n",
              "2023-02-17 08:00:00  [0, 1, 1, 2, 3, 3, 0, 2, 2, 3, 2, 2, 2, 2, 2, ...  \n",
              "2023-02-17 09:00:00  [1, 1, 2, 3, 3, 0, 2, 2, 3, 2, 2, 2, 2, 2, 1, ...  \n",
              "2023-02-17 10:00:00  [1, 2, 3, 3, 0, 2, 2, 3, 2, 2, 2, 2, 2, 1, 1, ...  \n",
              "2023-02-17 11:00:00  [3, 0, 2, 3, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, ...  \n",
              "2023-02-17 12:00:00  [0, 2, 3, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 1, ...  \n",
              "\n",
              "[5292 rows x 15 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "features=[\n",
        "    'temperature', 'humidity', 'pressure_msl', 'pressure_surface', \n",
        "    'global_irradiance', 'direct_irradiance', 'diffuse_irradiance', \n",
        "    'cloud_cover', 'wind_speed', 'wind_direction', 'precipitation', \n",
        "    'rain', 'showers', 'snowfall']\n",
        "def convert_columns_to_floats2(df, columns_to_convert):\n",
        "    for col in columns_to_convert:\n",
        "        print(f\"Processing column: {col}\")\n",
        "        df[col] = df[col].astype(str).apply(parse_complex_string)\n",
        "        print(f\"Processed column: {col}\")\n",
        "    return df\n",
        "def reduce_cells_for_all_columns(df, columns_to_reduce,n=int):\n",
        "    '''\n",
        "    Reduce each cell in each column by 96 values from the end\n",
        "    '''\n",
        "    for col in columns_to_reduce:\n",
        "        df[col] = df[col].apply(lambda x: x[:n] if len(x) > n else x + [None] * (n - len(x)))\n",
        "    return df\n",
        "def get_lengths_of_cells(df, columns):\n",
        "    '''\n",
        "    Get the lengths of cells in each specified column\n",
        "    '''\n",
        "    lengths = {col: df[col].apply(lambda x: len(x) if isinstance(x, list) else np.nan) for col in columns}\n",
        "    return pd.DataFrame(lengths)\n",
        "# df = convert_columns_to_numeric_lists(df, columns_to_convert2)\n",
        "df= convert_columns_to_floats2(df, features)\n",
        "lengths_df = get_lengths_of_cells(df, features)\n",
        "df= reduce_cells_for_all_columns(df, features, 96)\n",
        "# print(\"Lengths of cells before reduction:\")\n",
        "print(lengths_df)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import json \n",
        "# def safe_json_loads(x):\n",
        "#     if isinstance(x, str):\n",
        "#         try:\n",
        "#             return np.array(json.loads(x))\n",
        "#         except (json.JSONDecodeError, TypeError) as e:\n",
        "#             print(f\"Error parsing JSON for value: {x}, error: {e}\")\n",
        "#             return np.nan  # Or handle differently as needed\n",
        "#     elif isinstance(x, np.ndarray):\n",
        "#         return x\n",
        "#     else:\n",
        "#         return np.nan\n",
        "\n",
        "# # Apply JSON parsing to the DataFrame columns\n",
        "# for for_val in [\n",
        "#     'temperature', 'humidity', 'pressure_msl', 'pressure_surface', \n",
        "#     'global_irradiance', 'direct_irradiance', 'diffuse_irradiance', \n",
        "#     'cloud_cover', 'wind_speed', 'wind_direction', 'precipitation', \n",
        "#     'rain', 'showers', 'snowfall', 'weather_code'\n",
        "# ]:\n",
        "#     df[for_val] = df[for_val].map(safe_json_loads)\n",
        "\n",
        "# # Inspect the DataFrame to ensure proper parsing\n",
        "# df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # switch forecasts sequences from string to np array\n",
        "# import json\n",
        "# for for_val in [\n",
        "#     'temperature', 'humidity', 'pressure_msl', 'pressure_surface', \n",
        "#     'global_irradiance', 'direct_irradiance', 'diffuse_irradiance', \n",
        "#     'cloud_cover', 'wind_speed', 'wind_direction', 'precipitation', \n",
        "#     'rain', 'showers', 'snowfall', 'weather_code'\n",
        "# ]:\n",
        "#         df[for_val] = df[for_val].map(lambda x: np.array(json.loads(x)), na_action='ignore')\n",
        "# df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>temperature</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>timestamp</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2022-07-11 12:00:00</th>\n",
              "      <td>[22.0, 22.6, 23.1, 23.4, 23.2, 22.7, 21.6, 20....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-07-11 13:00:00</th>\n",
              "      <td>[22.6, 23.1, 23.4, 23.2, 22.7, 21.6, 20.3, 18....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-07-11 14:00:00</th>\n",
              "      <td>[23.2, 23.6, 23.5, 23.0, 22.1, 20.4, 18.9, 18....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-07-11 15:00:00</th>\n",
              "      <td>[23.6, 23.5, 23.0, 22.1, 20.4, 18.9, 18.2, 18....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-07-11 16:00:00</th>\n",
              "      <td>[23.5, 23.0, 22.1, 20.4, 18.9, 18.2, 18.0, 17....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-02-17 08:00:00</th>\n",
              "      <td>[4.0, 7.3, 10.3, 12.4, 13.9, 14.9, 15.9, 15.6,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-02-17 09:00:00</th>\n",
              "      <td>[7.3, 10.3, 12.4, 13.9, 14.9, 15.9, 15.6, 13.6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-02-17 10:00:00</th>\n",
              "      <td>[10.3, 12.4, 13.9, 14.9, 15.9, 15.6, 13.6, 10....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-02-17 11:00:00</th>\n",
              "      <td>[13.0, 14.2, 15.1, 15.4, 15.5, 13.7, 11.0, 8.7...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-02-17 12:00:00</th>\n",
              "      <td>[14.2, 15.1, 15.4, 15.5, 13.7, 11.0, 8.7, 7.4,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5292 rows Ã— 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                           temperature\n",
              "timestamp                                                             \n",
              "2022-07-11 12:00:00  [22.0, 22.6, 23.1, 23.4, 23.2, 22.7, 21.6, 20....\n",
              "2022-07-11 13:00:00  [22.6, 23.1, 23.4, 23.2, 22.7, 21.6, 20.3, 18....\n",
              "2022-07-11 14:00:00  [23.2, 23.6, 23.5, 23.0, 22.1, 20.4, 18.9, 18....\n",
              "2022-07-11 15:00:00  [23.6, 23.5, 23.0, 22.1, 20.4, 18.9, 18.2, 18....\n",
              "2022-07-11 16:00:00  [23.5, 23.0, 22.1, 20.4, 18.9, 18.2, 18.0, 17....\n",
              "...                                                                ...\n",
              "2023-02-17 08:00:00  [4.0, 7.3, 10.3, 12.4, 13.9, 14.9, 15.9, 15.6,...\n",
              "2023-02-17 09:00:00  [7.3, 10.3, 12.4, 13.9, 14.9, 15.9, 15.6, 13.6...\n",
              "2023-02-17 10:00:00  [10.3, 12.4, 13.9, 14.9, 15.9, 15.6, 13.6, 10....\n",
              "2023-02-17 11:00:00  [13.0, 14.2, 15.1, 15.4, 15.5, 13.7, 11.0, 8.7...\n",
              "2023-02-17 12:00:00  [14.2, 15.1, 15.4, 15.5, 13.7, 11.0, 8.7, 7.4,...\n",
              "\n",
              "[5292 rows x 1 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# pick one meteo variable\n",
        "meas = 'temperature'\n",
        "df_for = df.loc[:,[meas]]\n",
        "df_for"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precipitation</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>timestamp</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2022-07-11 12:00:00</th>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-07-11 13:00:00</th>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-07-11 14:00:00</th>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-07-11 15:00:00</th>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-07-11 16:00:00</th>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-02-17 08:00:00</th>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-02-17 09:00:00</th>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-02-17 10:00:00</th>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-02-17 11:00:00</th>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-02-17 12:00:00</th>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5292 rows Ã— 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                         precipitation\n",
              "timestamp                                                             \n",
              "2022-07-11 12:00:00  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
              "2022-07-11 13:00:00  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
              "2022-07-11 14:00:00  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
              "2022-07-11 15:00:00  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
              "2022-07-11 16:00:00  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
              "...                                                                ...\n",
              "2023-02-17 08:00:00  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
              "2023-02-17 09:00:00  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
              "2023-02-17 10:00:00  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
              "2023-02-17 11:00:00  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
              "2023-02-17 12:00:00  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
              "\n",
              "[5292 rows x 1 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# pick one meteo variable\n",
        "measP = 'precipitation'\n",
        "df_forP = df.loc[:,[measP]]\n",
        "df_forP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>temperature_forecast+0h</th>\n",
              "      <th>temperature_forecast+1h</th>\n",
              "      <th>temperature_forecast+2h</th>\n",
              "      <th>temperature_forecast+3h</th>\n",
              "      <th>temperature_forecast+4h</th>\n",
              "      <th>temperature_forecast+5h</th>\n",
              "      <th>temperature_forecast+6h</th>\n",
              "      <th>temperature_forecast+7h</th>\n",
              "      <th>temperature_forecast+8h</th>\n",
              "      <th>temperature_forecast+9h</th>\n",
              "      <th>...</th>\n",
              "      <th>temperature_forecast+86h</th>\n",
              "      <th>temperature_forecast+87h</th>\n",
              "      <th>temperature_forecast+88h</th>\n",
              "      <th>temperature_forecast+89h</th>\n",
              "      <th>temperature_forecast+90h</th>\n",
              "      <th>temperature_forecast+91h</th>\n",
              "      <th>temperature_forecast+92h</th>\n",
              "      <th>temperature_forecast+93h</th>\n",
              "      <th>temperature_forecast+94h</th>\n",
              "      <th>temperature_forecast+95h</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>timestamp</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2022-07-11 12:00:00</th>\n",
              "      <td>22.0</td>\n",
              "      <td>22.6</td>\n",
              "      <td>23.1</td>\n",
              "      <td>23.4</td>\n",
              "      <td>23.2</td>\n",
              "      <td>22.7</td>\n",
              "      <td>21.6</td>\n",
              "      <td>20.3</td>\n",
              "      <td>18.6</td>\n",
              "      <td>17.4</td>\n",
              "      <td>...</td>\n",
              "      <td>20.3</td>\n",
              "      <td>20.2</td>\n",
              "      <td>21.1</td>\n",
              "      <td>22.6</td>\n",
              "      <td>24.4</td>\n",
              "      <td>25.3</td>\n",
              "      <td>26.1</td>\n",
              "      <td>27.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>29.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-07-11 12:05:00</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-07-11 12:10:00</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-07-11 12:15:00</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-07-11 12:20:00</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-02-17 11:40:00</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-02-17 11:45:00</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-02-17 11:50:00</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-02-17 11:55:00</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-02-17 12:00:00</th>\n",
              "      <td>14.2</td>\n",
              "      <td>15.1</td>\n",
              "      <td>15.4</td>\n",
              "      <td>15.5</td>\n",
              "      <td>13.7</td>\n",
              "      <td>11.0</td>\n",
              "      <td>8.7</td>\n",
              "      <td>7.4</td>\n",
              "      <td>6.2</td>\n",
              "      <td>5.9</td>\n",
              "      <td>...</td>\n",
              "      <td>8.7</td>\n",
              "      <td>8.6</td>\n",
              "      <td>8.4</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.3</td>\n",
              "      <td>9.4</td>\n",
              "      <td>11.1</td>\n",
              "      <td>13.3</td>\n",
              "      <td>14.7</td>\n",
              "      <td>16.1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>63649 rows Ã— 96 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                     temperature_forecast+0h  temperature_forecast+1h  \\\n",
              "timestamp                                                               \n",
              "2022-07-11 12:00:00                     22.0                     22.6   \n",
              "2022-07-11 12:05:00                      NaN                      NaN   \n",
              "2022-07-11 12:10:00                      NaN                      NaN   \n",
              "2022-07-11 12:15:00                      NaN                      NaN   \n",
              "2022-07-11 12:20:00                      NaN                      NaN   \n",
              "...                                      ...                      ...   \n",
              "2023-02-17 11:40:00                      NaN                      NaN   \n",
              "2023-02-17 11:45:00                      NaN                      NaN   \n",
              "2023-02-17 11:50:00                      NaN                      NaN   \n",
              "2023-02-17 11:55:00                      NaN                      NaN   \n",
              "2023-02-17 12:00:00                     14.2                     15.1   \n",
              "\n",
              "                     temperature_forecast+2h  temperature_forecast+3h  \\\n",
              "timestamp                                                               \n",
              "2022-07-11 12:00:00                     23.1                     23.4   \n",
              "2022-07-11 12:05:00                      NaN                      NaN   \n",
              "2022-07-11 12:10:00                      NaN                      NaN   \n",
              "2022-07-11 12:15:00                      NaN                      NaN   \n",
              "2022-07-11 12:20:00                      NaN                      NaN   \n",
              "...                                      ...                      ...   \n",
              "2023-02-17 11:40:00                      NaN                      NaN   \n",
              "2023-02-17 11:45:00                      NaN                      NaN   \n",
              "2023-02-17 11:50:00                      NaN                      NaN   \n",
              "2023-02-17 11:55:00                      NaN                      NaN   \n",
              "2023-02-17 12:00:00                     15.4                     15.5   \n",
              "\n",
              "                     temperature_forecast+4h  temperature_forecast+5h  \\\n",
              "timestamp                                                               \n",
              "2022-07-11 12:00:00                     23.2                     22.7   \n",
              "2022-07-11 12:05:00                      NaN                      NaN   \n",
              "2022-07-11 12:10:00                      NaN                      NaN   \n",
              "2022-07-11 12:15:00                      NaN                      NaN   \n",
              "2022-07-11 12:20:00                      NaN                      NaN   \n",
              "...                                      ...                      ...   \n",
              "2023-02-17 11:40:00                      NaN                      NaN   \n",
              "2023-02-17 11:45:00                      NaN                      NaN   \n",
              "2023-02-17 11:50:00                      NaN                      NaN   \n",
              "2023-02-17 11:55:00                      NaN                      NaN   \n",
              "2023-02-17 12:00:00                     13.7                     11.0   \n",
              "\n",
              "                     temperature_forecast+6h  temperature_forecast+7h  \\\n",
              "timestamp                                                               \n",
              "2022-07-11 12:00:00                     21.6                     20.3   \n",
              "2022-07-11 12:05:00                      NaN                      NaN   \n",
              "2022-07-11 12:10:00                      NaN                      NaN   \n",
              "2022-07-11 12:15:00                      NaN                      NaN   \n",
              "2022-07-11 12:20:00                      NaN                      NaN   \n",
              "...                                      ...                      ...   \n",
              "2023-02-17 11:40:00                      NaN                      NaN   \n",
              "2023-02-17 11:45:00                      NaN                      NaN   \n",
              "2023-02-17 11:50:00                      NaN                      NaN   \n",
              "2023-02-17 11:55:00                      NaN                      NaN   \n",
              "2023-02-17 12:00:00                      8.7                      7.4   \n",
              "\n",
              "                     temperature_forecast+8h  temperature_forecast+9h  ...  \\\n",
              "timestamp                                                              ...   \n",
              "2022-07-11 12:00:00                     18.6                     17.4  ...   \n",
              "2022-07-11 12:05:00                      NaN                      NaN  ...   \n",
              "2022-07-11 12:10:00                      NaN                      NaN  ...   \n",
              "2022-07-11 12:15:00                      NaN                      NaN  ...   \n",
              "2022-07-11 12:20:00                      NaN                      NaN  ...   \n",
              "...                                      ...                      ...  ...   \n",
              "2023-02-17 11:40:00                      NaN                      NaN  ...   \n",
              "2023-02-17 11:45:00                      NaN                      NaN  ...   \n",
              "2023-02-17 11:50:00                      NaN                      NaN  ...   \n",
              "2023-02-17 11:55:00                      NaN                      NaN  ...   \n",
              "2023-02-17 12:00:00                      6.2                      5.9  ...   \n",
              "\n",
              "                     temperature_forecast+86h  temperature_forecast+87h  \\\n",
              "timestamp                                                                 \n",
              "2022-07-11 12:00:00                      20.3                      20.2   \n",
              "2022-07-11 12:05:00                       NaN                       NaN   \n",
              "2022-07-11 12:10:00                       NaN                       NaN   \n",
              "2022-07-11 12:15:00                       NaN                       NaN   \n",
              "2022-07-11 12:20:00                       NaN                       NaN   \n",
              "...                                       ...                       ...   \n",
              "2023-02-17 11:40:00                       NaN                       NaN   \n",
              "2023-02-17 11:45:00                       NaN                       NaN   \n",
              "2023-02-17 11:50:00                       NaN                       NaN   \n",
              "2023-02-17 11:55:00                       NaN                       NaN   \n",
              "2023-02-17 12:00:00                       8.7                       8.6   \n",
              "\n",
              "                     temperature_forecast+88h  temperature_forecast+89h  \\\n",
              "timestamp                                                                 \n",
              "2022-07-11 12:00:00                      21.1                      22.6   \n",
              "2022-07-11 12:05:00                       NaN                       NaN   \n",
              "2022-07-11 12:10:00                       NaN                       NaN   \n",
              "2022-07-11 12:15:00                       NaN                       NaN   \n",
              "2022-07-11 12:20:00                       NaN                       NaN   \n",
              "...                                       ...                       ...   \n",
              "2023-02-17 11:40:00                       NaN                       NaN   \n",
              "2023-02-17 11:45:00                       NaN                       NaN   \n",
              "2023-02-17 11:50:00                       NaN                       NaN   \n",
              "2023-02-17 11:55:00                       NaN                       NaN   \n",
              "2023-02-17 12:00:00                       8.4                       8.0   \n",
              "\n",
              "                     temperature_forecast+90h  temperature_forecast+91h  \\\n",
              "timestamp                                                                 \n",
              "2022-07-11 12:00:00                      24.4                      25.3   \n",
              "2022-07-11 12:05:00                       NaN                       NaN   \n",
              "2022-07-11 12:10:00                       NaN                       NaN   \n",
              "2022-07-11 12:15:00                       NaN                       NaN   \n",
              "2022-07-11 12:20:00                       NaN                       NaN   \n",
              "...                                       ...                       ...   \n",
              "2023-02-17 11:40:00                       NaN                       NaN   \n",
              "2023-02-17 11:45:00                       NaN                       NaN   \n",
              "2023-02-17 11:50:00                       NaN                       NaN   \n",
              "2023-02-17 11:55:00                       NaN                       NaN   \n",
              "2023-02-17 12:00:00                       8.3                       9.4   \n",
              "\n",
              "                     temperature_forecast+92h  temperature_forecast+93h  \\\n",
              "timestamp                                                                 \n",
              "2022-07-11 12:00:00                      26.1                      27.0   \n",
              "2022-07-11 12:05:00                       NaN                       NaN   \n",
              "2022-07-11 12:10:00                       NaN                       NaN   \n",
              "2022-07-11 12:15:00                       NaN                       NaN   \n",
              "2022-07-11 12:20:00                       NaN                       NaN   \n",
              "...                                       ...                       ...   \n",
              "2023-02-17 11:40:00                       NaN                       NaN   \n",
              "2023-02-17 11:45:00                       NaN                       NaN   \n",
              "2023-02-17 11:50:00                       NaN                       NaN   \n",
              "2023-02-17 11:55:00                       NaN                       NaN   \n",
              "2023-02-17 12:00:00                      11.1                      13.3   \n",
              "\n",
              "                     temperature_forecast+94h  temperature_forecast+95h  \n",
              "timestamp                                                                \n",
              "2022-07-11 12:00:00                      28.0                      29.0  \n",
              "2022-07-11 12:05:00                       NaN                       NaN  \n",
              "2022-07-11 12:10:00                       NaN                       NaN  \n",
              "2022-07-11 12:15:00                       NaN                       NaN  \n",
              "2022-07-11 12:20:00                       NaN                       NaN  \n",
              "...                                       ...                       ...  \n",
              "2023-02-17 11:40:00                       NaN                       NaN  \n",
              "2023-02-17 11:45:00                       NaN                       NaN  \n",
              "2023-02-17 11:50:00                       NaN                       NaN  \n",
              "2023-02-17 11:55:00                       NaN                       NaN  \n",
              "2023-02-17 12:00:00                      14.7                      16.1  \n",
              "\n",
              "[63649 rows x 96 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#unpack forecasts\n",
        "df_for.dropna(how='any',inplace=True)\n",
        "df_for_cols_ext = [meas+'_forecast+'+str(i)+'h' for i in range(0,len(df_for[meas].values[0]))]\n",
        "df_for = pd.DataFrame(index=df_for.index, data=df_for[meas].to_list(), columns=df_for_cols_ext)\n",
        "\n",
        "df_for = df_for.asfreq('5min')\n",
        "df_for"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precipitation_forecast+0h</th>\n",
              "      <th>precipitation_forecast+1h</th>\n",
              "      <th>precipitation_forecast+2h</th>\n",
              "      <th>precipitation_forecast+3h</th>\n",
              "      <th>precipitation_forecast+4h</th>\n",
              "      <th>precipitation_forecast+5h</th>\n",
              "      <th>precipitation_forecast+6h</th>\n",
              "      <th>precipitation_forecast+7h</th>\n",
              "      <th>precipitation_forecast+8h</th>\n",
              "      <th>precipitation_forecast+9h</th>\n",
              "      <th>...</th>\n",
              "      <th>precipitation_forecast+86h</th>\n",
              "      <th>precipitation_forecast+87h</th>\n",
              "      <th>precipitation_forecast+88h</th>\n",
              "      <th>precipitation_forecast+89h</th>\n",
              "      <th>precipitation_forecast+90h</th>\n",
              "      <th>precipitation_forecast+91h</th>\n",
              "      <th>precipitation_forecast+92h</th>\n",
              "      <th>precipitation_forecast+93h</th>\n",
              "      <th>precipitation_forecast+94h</th>\n",
              "      <th>precipitation_forecast+95h</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>timestamp</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2022-07-11 12:00:00</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-07-11 12:05:00</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-07-11 12:10:00</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-07-11 12:15:00</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-07-11 12:20:00</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-02-17 11:40:00</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-02-17 11:45:00</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-02-17 11:50:00</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-02-17 11:55:00</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-02-17 12:00:00</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>63649 rows Ã— 96 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                     precipitation_forecast+0h  precipitation_forecast+1h  \\\n",
              "timestamp                                                                   \n",
              "2022-07-11 12:00:00                        0.0                        0.0   \n",
              "2022-07-11 12:05:00                        NaN                        NaN   \n",
              "2022-07-11 12:10:00                        NaN                        NaN   \n",
              "2022-07-11 12:15:00                        NaN                        NaN   \n",
              "2022-07-11 12:20:00                        NaN                        NaN   \n",
              "...                                        ...                        ...   \n",
              "2023-02-17 11:40:00                        NaN                        NaN   \n",
              "2023-02-17 11:45:00                        NaN                        NaN   \n",
              "2023-02-17 11:50:00                        NaN                        NaN   \n",
              "2023-02-17 11:55:00                        NaN                        NaN   \n",
              "2023-02-17 12:00:00                        0.0                        0.0   \n",
              "\n",
              "                     precipitation_forecast+2h  precipitation_forecast+3h  \\\n",
              "timestamp                                                                   \n",
              "2022-07-11 12:00:00                        0.0                        0.0   \n",
              "2022-07-11 12:05:00                        NaN                        NaN   \n",
              "2022-07-11 12:10:00                        NaN                        NaN   \n",
              "2022-07-11 12:15:00                        NaN                        NaN   \n",
              "2022-07-11 12:20:00                        NaN                        NaN   \n",
              "...                                        ...                        ...   \n",
              "2023-02-17 11:40:00                        NaN                        NaN   \n",
              "2023-02-17 11:45:00                        NaN                        NaN   \n",
              "2023-02-17 11:50:00                        NaN                        NaN   \n",
              "2023-02-17 11:55:00                        NaN                        NaN   \n",
              "2023-02-17 12:00:00                        0.0                        0.0   \n",
              "\n",
              "                     precipitation_forecast+4h  precipitation_forecast+5h  \\\n",
              "timestamp                                                                   \n",
              "2022-07-11 12:00:00                        0.0                        0.0   \n",
              "2022-07-11 12:05:00                        NaN                        NaN   \n",
              "2022-07-11 12:10:00                        NaN                        NaN   \n",
              "2022-07-11 12:15:00                        NaN                        NaN   \n",
              "2022-07-11 12:20:00                        NaN                        NaN   \n",
              "...                                        ...                        ...   \n",
              "2023-02-17 11:40:00                        NaN                        NaN   \n",
              "2023-02-17 11:45:00                        NaN                        NaN   \n",
              "2023-02-17 11:50:00                        NaN                        NaN   \n",
              "2023-02-17 11:55:00                        NaN                        NaN   \n",
              "2023-02-17 12:00:00                        0.0                        0.0   \n",
              "\n",
              "                     precipitation_forecast+6h  precipitation_forecast+7h  \\\n",
              "timestamp                                                                   \n",
              "2022-07-11 12:00:00                        0.0                        0.0   \n",
              "2022-07-11 12:05:00                        NaN                        NaN   \n",
              "2022-07-11 12:10:00                        NaN                        NaN   \n",
              "2022-07-11 12:15:00                        NaN                        NaN   \n",
              "2022-07-11 12:20:00                        NaN                        NaN   \n",
              "...                                        ...                        ...   \n",
              "2023-02-17 11:40:00                        NaN                        NaN   \n",
              "2023-02-17 11:45:00                        NaN                        NaN   \n",
              "2023-02-17 11:50:00                        NaN                        NaN   \n",
              "2023-02-17 11:55:00                        NaN                        NaN   \n",
              "2023-02-17 12:00:00                        0.0                        0.0   \n",
              "\n",
              "                     precipitation_forecast+8h  precipitation_forecast+9h  \\\n",
              "timestamp                                                                   \n",
              "2022-07-11 12:00:00                        0.0                        0.0   \n",
              "2022-07-11 12:05:00                        NaN                        NaN   \n",
              "2022-07-11 12:10:00                        NaN                        NaN   \n",
              "2022-07-11 12:15:00                        NaN                        NaN   \n",
              "2022-07-11 12:20:00                        NaN                        NaN   \n",
              "...                                        ...                        ...   \n",
              "2023-02-17 11:40:00                        NaN                        NaN   \n",
              "2023-02-17 11:45:00                        NaN                        NaN   \n",
              "2023-02-17 11:50:00                        NaN                        NaN   \n",
              "2023-02-17 11:55:00                        NaN                        NaN   \n",
              "2023-02-17 12:00:00                        0.0                        0.0   \n",
              "\n",
              "                     ...  precipitation_forecast+86h  \\\n",
              "timestamp            ...                               \n",
              "2022-07-11 12:00:00  ...                         0.0   \n",
              "2022-07-11 12:05:00  ...                         NaN   \n",
              "2022-07-11 12:10:00  ...                         NaN   \n",
              "2022-07-11 12:15:00  ...                         NaN   \n",
              "2022-07-11 12:20:00  ...                         NaN   \n",
              "...                  ...                         ...   \n",
              "2023-02-17 11:40:00  ...                         NaN   \n",
              "2023-02-17 11:45:00  ...                         NaN   \n",
              "2023-02-17 11:50:00  ...                         NaN   \n",
              "2023-02-17 11:55:00  ...                         NaN   \n",
              "2023-02-17 12:00:00  ...                         0.0   \n",
              "\n",
              "                     precipitation_forecast+87h  precipitation_forecast+88h  \\\n",
              "timestamp                                                                     \n",
              "2022-07-11 12:00:00                         0.0                         0.0   \n",
              "2022-07-11 12:05:00                         NaN                         NaN   \n",
              "2022-07-11 12:10:00                         NaN                         NaN   \n",
              "2022-07-11 12:15:00                         NaN                         NaN   \n",
              "2022-07-11 12:20:00                         NaN                         NaN   \n",
              "...                                         ...                         ...   \n",
              "2023-02-17 11:40:00                         NaN                         NaN   \n",
              "2023-02-17 11:45:00                         NaN                         NaN   \n",
              "2023-02-17 11:50:00                         NaN                         NaN   \n",
              "2023-02-17 11:55:00                         NaN                         NaN   \n",
              "2023-02-17 12:00:00                         0.0                         0.0   \n",
              "\n",
              "                     precipitation_forecast+89h  precipitation_forecast+90h  \\\n",
              "timestamp                                                                     \n",
              "2022-07-11 12:00:00                         0.0                         0.0   \n",
              "2022-07-11 12:05:00                         NaN                         NaN   \n",
              "2022-07-11 12:10:00                         NaN                         NaN   \n",
              "2022-07-11 12:15:00                         NaN                         NaN   \n",
              "2022-07-11 12:20:00                         NaN                         NaN   \n",
              "...                                         ...                         ...   \n",
              "2023-02-17 11:40:00                         NaN                         NaN   \n",
              "2023-02-17 11:45:00                         NaN                         NaN   \n",
              "2023-02-17 11:50:00                         NaN                         NaN   \n",
              "2023-02-17 11:55:00                         NaN                         NaN   \n",
              "2023-02-17 12:00:00                         0.0                         0.0   \n",
              "\n",
              "                     precipitation_forecast+91h  precipitation_forecast+92h  \\\n",
              "timestamp                                                                     \n",
              "2022-07-11 12:00:00                         0.0                         0.0   \n",
              "2022-07-11 12:05:00                         NaN                         NaN   \n",
              "2022-07-11 12:10:00                         NaN                         NaN   \n",
              "2022-07-11 12:15:00                         NaN                         NaN   \n",
              "2022-07-11 12:20:00                         NaN                         NaN   \n",
              "...                                         ...                         ...   \n",
              "2023-02-17 11:40:00                         NaN                         NaN   \n",
              "2023-02-17 11:45:00                         NaN                         NaN   \n",
              "2023-02-17 11:50:00                         NaN                         NaN   \n",
              "2023-02-17 11:55:00                         NaN                         NaN   \n",
              "2023-02-17 12:00:00                         0.0                         0.0   \n",
              "\n",
              "                     precipitation_forecast+93h  precipitation_forecast+94h  \\\n",
              "timestamp                                                                     \n",
              "2022-07-11 12:00:00                         0.0                         0.0   \n",
              "2022-07-11 12:05:00                         NaN                         NaN   \n",
              "2022-07-11 12:10:00                         NaN                         NaN   \n",
              "2022-07-11 12:15:00                         NaN                         NaN   \n",
              "2022-07-11 12:20:00                         NaN                         NaN   \n",
              "...                                         ...                         ...   \n",
              "2023-02-17 11:40:00                         NaN                         NaN   \n",
              "2023-02-17 11:45:00                         NaN                         NaN   \n",
              "2023-02-17 11:50:00                         NaN                         NaN   \n",
              "2023-02-17 11:55:00                         NaN                         NaN   \n",
              "2023-02-17 12:00:00                         0.0                         0.0   \n",
              "\n",
              "                     precipitation_forecast+95h  \n",
              "timestamp                                        \n",
              "2022-07-11 12:00:00                         0.0  \n",
              "2022-07-11 12:05:00                         NaN  \n",
              "2022-07-11 12:10:00                         NaN  \n",
              "2022-07-11 12:15:00                         NaN  \n",
              "2022-07-11 12:20:00                         NaN  \n",
              "...                                         ...  \n",
              "2023-02-17 11:40:00                         NaN  \n",
              "2023-02-17 11:45:00                         NaN  \n",
              "2023-02-17 11:50:00                         NaN  \n",
              "2023-02-17 11:55:00                         NaN  \n",
              "2023-02-17 12:00:00                         0.0  \n",
              "\n",
              "[63649 rows x 96 columns]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#unpack forecasts\n",
        "df_forP.dropna(how='any',inplace=True)\n",
        "df_for_cols_ext = [measP+'_forecast+'+str(i)+'h' for i in range(0,len(df_forP[measP].values[0]))]\n",
        "df_forP = pd.DataFrame(index=df_forP.index, data=df_forP[measP].to_list(), columns=df_for_cols_ext)\n",
        "df_forP = df_forP.asfreq('5min')\n",
        "df_forP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "dfT=df_for.fillna(method='ffill')\n",
        "dfP = df_forP.interpolate(method='linear', limit_direction='forward', axis=0)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# reduce memory usage\n",
        "dfT= reduce_mem_usage(dfT)\n",
        "dfP= reduce_mem_usage(dfP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dfT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dfP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Convert specific columns to lists of floats\n",
        "# # columns_to_convert1 = [\n",
        "# #     'temperature', 'humidity', 'pressure',\t'cloud_cover',\t'wind_speed',\n",
        "# #         \t'wind_direction',\t'weather_code'\t,'poprecipitation'\n",
        "# # ]\n",
        "\n",
        "# columns_to_convert2 = [\n",
        "#     'temperature', 'humidity', 'pressure',\n",
        "#     'cloud_cover', 'wind_speed', 'wind_direction', 'poprecipitation',\n",
        "#      'weather_code'\n",
        "# ]\n",
        "# def parse_complex_string(s):\n",
        "#     try:\n",
        "#         return [float(x) for x in s.strip('[]').split(',')]\n",
        "#     except ValueError:\n",
        "#         return s\n",
        "\n",
        "# # Function to convert columns to lists of floats\n",
        "# def convert_columns_to_numeric_lists(df, columns_to_convert):\n",
        "#     for col in columns_to_convert:\n",
        "#         df[col] = df[col].astype(str).apply(parse_complex_string)\n",
        "#     return df\n",
        "\n",
        "# def convert_columns_to_floats2(df, columns_to_convert):\n",
        "#     for col in columns_to_convert:\n",
        "#         print(f\"Processing column: {col}\")\n",
        "#         df[col] = df[col].astype(str).apply(parse_complex_string)\n",
        "#         print(f\"Processed column: {col}\")\n",
        "#     return df\n",
        "\n",
        "# def flatten_columns(df, columns_to_flatten):\n",
        "#     for col in columns_to_flatten:\n",
        "#         df[col] = df[col].apply(lambda x: np.mean(x) if isinstance(x, list) else x)\n",
        "#     return df\n",
        "# def reduce_cells_for_all_columns(df, columns_to_reduce,n=int):\n",
        "#     '''\n",
        "#     Reduce each cell in each column by 96 values from the end\n",
        "#     '''\n",
        "#     for cols in columns_to_reduce:\n",
        "#         df[cols] = df[cols].apply(lambda x: x[:-n])\n",
        "#     return df\n",
        "# def get_lengths_of_cells(df, columns):\n",
        "#     '''\n",
        "#     Get the lengths of cells in each specified column\n",
        "#     '''\n",
        "#     lengths = {col: df[col].apply(lambda x: len(x) if isinstance(x, list) else np.nan) for col in columns}\n",
        "#     return pd.DataFrame(lengths)\n",
        "# df = convert_columns_to_numeric_lists(df, columns_to_convert2)\n",
        "# # df= convert_columns_to_floats2(df, columns_to_convert2)\n",
        "# # lengths_df = get_lengths_of_cells(df, columns_to_convert2)\n",
        "\n",
        "# # print(\"Lengths of cells before reduction:\")\n",
        "# # print(lengths_df)\n",
        "# # df = convert_columns_to_floats2(df, columns_to_convert1)\n",
        "\n",
        "# # # Flatten the columns\n",
        "# # # df= reduce_cells_for_all_columns(df,columns_to_convert2,n=72)\n",
        "# # # df = flatten_columns(df, columns_to_convert1)\n",
        "# # df = flatten_columns(df, columns_to_convert2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Function to aggregate list features\n",
        "# def aggregate_features(df, columns_to_aggregate):\n",
        "#     for col in columns_to_aggregate:\n",
        "#         df[f'{col}_mean'] = df[col].apply(lambda x: np.mean(x) if isinstance(x, list) else x)\n",
        "#         df[f'{col}_std'] = df[col].apply(lambda x: np.std(x) if isinstance(x, list) else 0)\n",
        "#         df[f'{col}_min'] = df[col].apply(lambda x: np.min(x) if isinstance(x, list) else x)\n",
        "#         df[f'{col}_max'] = df[col].apply(lambda x: np.max(x) if isinstance(x, list) else x)\n",
        "#         # Drop original column if not needed\n",
        "#         df.drop(columns=[col], inplace=True)\n",
        "#     return df\n",
        "\n",
        "# # Aggregate the columns\n",
        "# df = aggregate_features(df, columns_to_convert2)\n",
        "\n",
        "# print(\"\\nDataFrame with aggregated features:\")\n",
        "# print(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
        "# df.set_index('timestamp', inplace=True)\n",
        "\n",
        "# # Resample and aggregate the data to every 5 minutes\n",
        "# df = df.resample('5T').agg({\n",
        "#     'temperature_mean': 'mean', 'temperature_std': 'mean', 'temperature_min': 'mean', 'temperature_max': 'mean',\n",
        "#     'humidity_mean': 'mean', 'humidity_std': 'mean', 'humidity_min': 'mean', 'humidity_max': 'mean',\n",
        "#     'pressure_mean': 'mean', 'pressure_std': 'mean', 'pressure_min': 'mean', 'pressure_max': 'mean',\n",
        "#     'cloud_cover_mean': 'mean', 'cloud_cover_std': 'mean', 'cloud_cover_min': 'mean', 'cloud_cover_max': 'mean',\n",
        "#     'wind_speed_mean': 'mean', 'wind_speed_std': 'mean', 'wind_speed_min': 'mean', 'wind_speed_max': 'mean',\n",
        "#     'wind_direction_mean': 'mean', 'wind_direction_std': 'mean', 'wind_direction_min': 'mean', 'wind_direction_max': 'mean',\n",
        "#     'poprecipitation_mean': 'sum', 'poprecipitation_std': 'sum', 'poprecipitation_min': 'sum', 'poprecipitation_max': 'sum',\n",
        "#     'weather_code_mean': 'sum', 'weather_code_std': 'sum', 'weather_code_min': 'sum', 'weather_code_max': 'sum'\n",
        "# })\n",
        "\n",
        "# df.head()\n",
        "# df.isnull().sum()\n",
        "# df = df.fillna(method='ffill')\n",
        "# df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Convert timestamp to datetime and set as index\n",
        "# df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
        "# df.set_index('timestamp', inplace=True)\n",
        "\n",
        "# # Fill missing values using forward fill\n",
        "# # df = df.fillna(method='ffill')\n",
        "\n",
        "# # # Plot univariate data (temperature)\n",
        "# # uni_data = df['temperature']\n",
        "# # uni_data.plot()\n",
        "\n",
        "# # Resample and aggregate the data\n",
        "# df = df.resample('10T').agg({\n",
        "#     'temperature': 'mean',  \n",
        "#     'humidity': 'mean',     \n",
        "#     'pressure': 'mean',  \n",
        "    \n",
        "#     'cloud_cover': 'mean',\n",
        "#     'wind_speed': 'mean',\n",
        "#     'wind_direction': 'mean',\n",
        "#     'poprecipitation': 'sum',\n",
        "    \n",
        "#     'weather_code': 'sum'\n",
        "# })\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kBZ2zKYtq2kl"
      },
      "source": [
        "Observations:\n",
        "1) One reading evrry 10 mins (from datatime column time diff for every record )\n",
        "2) 1day = 6*24 = 144 readings\n",
        "Task : Forecasting Temperature(in degree ) in future \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# import pandas as pd\n",
        "\n",
        "# Assuming 'df' is the DataFrame that contains the temperature forecast data.\n",
        "\n",
        "# List of column names for temperature forecast features\n",
        "temperature_cols = [\n",
        "    'temperature_forecast+0h', 'temperature_forecast+1h', 'temperature_forecast+2h', \n",
        "    'temperature_forecast+3h', 'temperature_forecast+4h', 'temperature_forecast+5h', \n",
        "    'temperature_forecast+6h', 'temperature_forecast+7h', 'temperature_forecast+8h', \n",
        "    'temperature_forecast+9h', 'temperature_forecast+10h', 'temperature_forecast+11h', \n",
        "    'temperature_forecast+12h', 'temperature_forecast+13h', 'temperature_forecast+14h', \n",
        "    'temperature_forecast+15h', 'temperature_forecast+16h', 'temperature_forecast+17h', \n",
        "    'temperature_forecast+18h', 'temperature_forecast+19h', 'temperature_forecast+20h', \n",
        "    'temperature_forecast+21h', 'temperature_forecast+22h', 'temperature_forecast+23h', \n",
        "    'temperature_forecast+24h', 'temperature_forecast+25h', 'temperature_forecast+26h', \n",
        "    'temperature_forecast+27h', 'temperature_forecast+28h', 'temperature_forecast+29h', \n",
        "    'temperature_forecast+30h', 'temperature_forecast+31h', 'temperature_forecast+32h', \n",
        "    'temperature_forecast+33h', 'temperature_forecast+34h', 'temperature_forecast+35h', \n",
        "    'temperature_forecast+36h', 'temperature_forecast+37h', 'temperature_forecast+38h', \n",
        "    'temperature_forecast+39h', 'temperature_forecast+40h', 'temperature_forecast+41h', \n",
        "    'temperature_forecast+42h', 'temperature_forecast+43h', 'temperature_forecast+44h', \n",
        "    'temperature_forecast+45h', 'temperature_forecast+46h', 'temperature_forecast+47h'\n",
        "]\n",
        "\n",
        "# Select the temperature forecast columns from the DataFrame\n",
        "temperature_features = dfT[temperature_cols]\n",
        "\n",
        "# Convert the DataFrame to numpy array\n",
        "scaler_temp = StandardScaler()\n",
        "\n",
        "\n",
        "# Fit and transform the scaler on training data\n",
        "uni_data_temp = scaler_temp.fit_transform(temperature_features.values)\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "train_split = int(len(uni_data_temp) * 0.8)\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "tf.random.set_seed(13)\n",
        "\n",
        "# Check the shape of the data to ensure it is correct\n",
        "print(\"Shape of uni_data_temp:\", uni_data_temp.shape)\n",
        "print(\"Training data shape:\", uni_data_temp[:train_split].shape)\n",
        "print(\"Validation data shape:\", uni_data_temp[train_split:].shape)\n",
        "\n",
        "\n",
        "# # Standardize data\n",
        "# uni_data_temp_mean = uni_data_temp[:train_split].mean(axis=0)\n",
        "# uni_data_temp_std = uni_data_temp[:train_split].std(axis=0)\n",
        "# uni_data_temp = (uni_data_temp - uni_data_temp_mean) / uni_data_temp_std\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to create data for univariate forecasting\n",
        "def univariate_data(dataset, start_idx, end_idx, history_size, target_size):\n",
        "    data = []\n",
        "    labels = []\n",
        "    start_idx = start_idx + history_size\n",
        "    if end_idx is None:\n",
        "        end_idx = len(dataset) - target_size\n",
        "    for i in range(start_idx, end_idx):\n",
        "        idxs = range(i - history_size, i)\n",
        "        data.append(dataset[idxs])\n",
        "        labels.append(dataset[i + target_size])\n",
        "    return np.array(data), np.array(labels)\n",
        "\n",
        "uni_data_history = 20  # Last 20 values\n",
        "uni_data_future = 0    # Future data\n",
        "\n",
        "x_train_uni_temp, y_train_uni_temp = univariate_data(uni_data_temp, 0, train_split, uni_data_history, uni_data_future)\n",
        "x_val_uni_temp, y_val_uni_temp = univariate_data(uni_data_temp, train_split, None, uni_data_history, uni_data_future)\n",
        "\n",
        "print(x_train_uni_temp.shape)  # (151495, 20, 4)\n",
        "print(y_train_uni_temp.shape)  # (151495, 4)\n",
        "print(x_val_uni_temp.shape)    # (37859, 20, 4)\n",
        "print(y_val_uni_temp.shape)    # (37859, 4)\n",
        "\n",
        "# Function to create time steps\n",
        "def create_time_steps(length):\n",
        "    return list(range(-length, 0))\n",
        "\n",
        "# Function to plot time series data\n",
        "def plot_time_series(plot_data, delta, title):\n",
        "    labels = [\"History\", \"True Future\", \"Model Predicted\"]\n",
        "    marker = ['.-', 'rx', 'go']\n",
        "    time_steps = create_time_steps(plot_data[0].shape[0])\n",
        "\n",
        "    plt.title(title)\n",
        "    for i, x in enumerate(plot_data):\n",
        "        if i == 0:\n",
        "            plt.plot(time_steps, plot_data[i][:, 0], marker[i], label=labels[i])  # Plot only the first feature for simplicity\n",
        "        else:\n",
        "            future = time_steps[-1] + 1\n",
        "            plt.plot([future], plot_data[i], marker[i], markersize=10, label=labels[i])  # Plot single future point\n",
        "    plt.legend()\n",
        "    plt.xlabel('Time Steps')\n",
        "    plt.show()\n",
        "\n",
        "# Example of plotting the first sample\n",
        "plot_time_series([x_train_uni_temp[0], y_train_uni_temp[0][0]], 0, 'Sample Example - Temperature')\n",
        "\n",
        "# Example of plotting another sample\n",
        "i = 20\n",
        "plot_time_series([x_train_uni_temp[i], y_train_uni_temp[i][0]], 0, 'Sample Example - Temperature')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare the univar# Define the columns for precipitation forecasts\n",
        "precipitation_cols = [\n",
        "    'precipitation_forecast+0h', 'precipitation_forecast+1h', 'precipitation_forecast+2h',\n",
        "    'precipitation_forecast+3h', 'precipitation_forecast+4h', 'precipitation_forecast+5h',\n",
        "    'precipitation_forecast+6h', 'precipitation_forecast+7h', 'precipitation_forecast+8h',\n",
        "    'precipitation_forecast+9h', 'precipitation_forecast+10h', 'precipitation_forecast+11h',\n",
        "    'precipitation_forecast+12h', 'precipitation_forecast+13h', 'precipitation_forecast+14h',\n",
        "    'precipitation_forecast+15h', 'precipitation_forecast+16h', 'precipitation_forecast+17h',\n",
        "    'precipitation_forecast+18h', 'precipitation_forecast+19h', 'precipitation_forecast+20h',\n",
        "    'precipitation_forecast+21h', 'precipitation_forecast+22h', 'precipitation_forecast+23h',\n",
        "    'precipitation_forecast+24h', 'precipitation_forecast+25h', 'precipitation_forecast+26h',\n",
        "    'precipitation_forecast+27h', 'precipitation_forecast+28h', 'precipitation_forecast+29h',\n",
        "    'precipitation_forecast+30h', 'precipitation_forecast+31h', 'precipitation_forecast+32h',\n",
        "    'precipitation_forecast+33h', 'precipitation_forecast+34h', 'precipitation_forecast+35h',\n",
        "    'precipitation_forecast+36h', 'precipitation_forecast+37h', 'precipitation_forecast+38h',\n",
        "    'precipitation_forecast+39h', 'precipitation_forecast+40h', 'precipitation_forecast+41h',\n",
        "    'precipitation_forecast+42h', 'precipitation_forecast+43h', 'precipitation_forecast+44h',\n",
        "    'precipitation_forecast+45h', 'precipitation_forecast+46h', 'precipitation_forecast+47h'\n",
        "]\n",
        "\n",
        "# Extract precipitation forecast features\n",
        "precipitation_features = dfP[precipitation_cols]\n",
        "\n",
        "scaler_precip = StandardScaler()\n",
        "uni_data_precip = scaler_precip.fit_transform(precipitation_features.values)\n",
        "\n",
        "# Assuming train_split is already defined appropriately\n",
        "tf.random.set_seed(13)\n",
        "\n",
        "\n",
        "# # Standardize data\n",
        "# uni_data_precip_mean = uni_data_precip[:train_split].mean(axis=0)\n",
        "# uni_data_precip_std = uni_data_precip[:train_split].std(axis=0)\n",
        "# uni_data_precip = (uni_data_precip - uni_data_precip_mean) / uni_data_precip_std\n",
        "\n",
        "x_train_uni_precip, y_train_uni_precip = univariate_data(uni_data_precip, 0, train_split, uni_data_history, uni_data_future)\n",
        "x_val_uni_precip, y_val_uni_precip = univariate_data(uni_data_precip, train_split, None, uni_data_history, uni_data_future)\n",
        "x_train_uni_precip.shape, y_train_uni_precip.shape\n",
        "x_val_uni_precip.shape, y_val_uni_precip.shape\n",
        "\n",
        "plot_time_series([x_train_uni_precip[0], y_train_uni_precip[0][0]], 0, 'Sample Example - Precipitation')\n",
        "i = 20\n",
        "plot_time_series([x_train_uni_precip[i], y_train_uni_precip[i][0]], 0, 'Sample Example - Precipitation')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare tensorflow dataset for univariate temperature model\n",
        "batch_size = 256\n",
        "buffer_size = 10000\n",
        "\n",
        "train_uni_temp = tf.data.Dataset.from_tensor_slices((x_train_uni_temp, y_train_uni_temp))\n",
        "train_uni_temp = train_uni_temp.cache().shuffle(buffer_size).batch(batch_size).repeat()\n",
        "\n",
        "val_uni_temp = tf.data.Dataset.from_tensor_slices((x_val_uni_temp, y_val_uni_temp))\n",
        "val_uni_temp = val_uni_temp.cache().shuffle(buffer_size).batch(batch_size).repeat()\n",
        "\n",
        "# # Prepare tensorflow dataset for univariate precipitation model\n",
        "train_uni_precip = tf.data.Dataset.from_tensor_slices((x_train_uni_precip, y_train_uni_precip))\n",
        "train_uni_precip = train_uni_precip.cache().shuffle(buffer_size).batch(batch_size).repeat()\n",
        "\n",
        "val_uni_precip = tf.data.Dataset.from_tensor_slices((x_val_uni_precip, y_val_uni_precip))\n",
        "val_uni_precip = val_uni_precip.cache().shuffle(buffer_size).batch(batch_size).repeat()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define LSTM model for temperature\n",
        "lstm_model_temp = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.LSTM(32, input_shape=x_train_uni_temp.shape[-2:]),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model with optimizer and loss function\n",
        "lstm_model_temp.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "                        loss='mae')\n",
        "\n",
        "# Print model summary\n",
        "lstm_model_temp.summary()\n",
        "\n",
        "# Train LSTM model for temperature\n",
        "EVALUATION_INTERVAL = 200\n",
        "EPOCHS = 10\n",
        "\n",
        "temp_history = lstm_model_temp.fit(train_uni_temp, epochs=EPOCHS, steps_per_epoch=EVALUATION_INTERVAL,\n",
        "                                   validation_data=val_uni_temp, validation_steps=50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mae_lstm_single = lstm_model_temp.evaluate(val_uni_temp, steps=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define LSTM model for precipitation\n",
        "lstm_model_precip = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.LSTM(32, input_shape=x_train_uni_precip.shape[-2:]),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "lstm_model_precip.compile(optimizer='adam', loss='mae')\n",
        "lstm_model_precip.summary()\n",
        "\n",
        "# Train LSTM model for precipitation\n",
        "precip_history = lstm_model_precip.fit(train_uni_precip, epochs=EPOCHS, steps_per_epoch=EVALUATION_INTERVAL,\n",
        "                                       validation_data=val_uni_precip, validation_steps=50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mae_lstm_single = lstm_model_precip.evaluate(val_uni_precip, steps=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plotting function for training history\n",
        "def plot_train_history(history, title):\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "    epochs = range(len(loss))\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "    plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "    plt.title(title)\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "plot_train_history(temp_history, 'Temperature Training and Validation Loss')\n",
        "plot_train_history(precip_history, 'Precipitation Training and Validation Loss')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming the variables like train_split, buffer_size, batch_size, create_time_steps are defined appropriately\n",
        "\n",
        "# Multivariate model using selected features\n",
        "features = [\n",
        "    'temperature_mean', 'temperature_std', 'temperature_min', 'temperature_max',\n",
        "    'humidity_mean', 'humidity_std', 'humidity_min', 'humidity_max',\n",
        "    'poprecipitation_mean', 'poprecipitation_std', 'poprecipitation_min', 'poprecipitation_max'\n",
        "]\n",
        "\n",
        "# Filter the DataFrame to include only the selected features\n",
        "multi_features = df[features].values\n",
        "\n",
        "# Normalize the features\n",
        "multi_data_mean = multi_features[:train_split].mean(axis=0)\n",
        "multi_data_std = multi_features[:train_split].std(axis=0)\n",
        "multi_features = (multi_features - multi_data_mean) / multi_data_std\n",
        "\n",
        "# Function to create multivariate data\n",
        "def multivariate_data(dataset, target, start_index, end_index, history_size,\n",
        "                      target_size, step, single_step=False):\n",
        "    data = []\n",
        "    labels = []\n",
        "\n",
        "    end_index = end_index if end_index is not None else len(dataset) - target_size\n",
        "    start_index = start_index + history_size\n",
        "\n",
        "    for i in range(start_index, end_index):\n",
        "        indices = range(i - history_size, i, step)\n",
        "        data.append(dataset[indices])\n",
        "\n",
        "        if single_step:\n",
        "            labels.append(target[i + target_size])\n",
        "        else:\n",
        "            labels.append(target[i:i + target_size])\n",
        "\n",
        "    return np.array(data), np.array(labels)\n",
        "\n",
        "history_size = 1440\n",
        "target_size = 144\n",
        "STEP = 6\n",
        "\n",
        "# Create training and validation data\n",
        "x_train_multi, y_train_multi = multivariate_data(multi_features, multi_features[:, 0], 0, train_split, history_size, target_size, STEP, single_step=True)\n",
        "x_val_multi, y_val_multi = multivariate_data(multi_features, multi_features[:, 0], train_split, None, history_size, target_size, STEP, single_step=True)\n",
        "\n",
        "# Create TensorFlow datasets\n",
        "train_data_multi = tf.data.Dataset.from_tensor_slices((x_train_multi, y_train_multi))\n",
        "train_data_multi = train_data_multi.cache().shuffle(buffer_size).batch(batch_size).repeat()\n",
        "\n",
        "val_data_multi = tf.data.Dataset.from_tensor_slices((x_val_multi, y_val_multi))\n",
        "val_data_multi = val_data_multi.cache().shuffle(buffer_size).batch(batch_size).repeat()\n",
        "\n",
        "# Multivariate LSTM model\n",
        "multi_step_model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.LSTM(64, return_sequences=True, input_shape=x_train_multi.shape[-2:]),\n",
        "    tf.keras.layers.LSTM(16, return_sequences=False, activation='relu'),\n",
        "    tf.keras.layers.Dense(4, activation='relu'),  # Additional dense layer if needed\n",
        "    tf.keras.layers.Dense(target_size)  # Output layer predicting 144 time steps into the future\n",
        "])\n",
        "\n",
        "multi_step_model.compile(optimizer='adam', loss='mae')\n",
        "\n",
        "# Verify model output shape\n",
        "for x, y in val_data_multi.take(1):\n",
        "    print(\"Model Output Shape:\", multi_step_model.predict(x).shape)\n",
        "\n",
        "# Define training parameters\n",
        "EVALUATION_INTERVAL = 200\n",
        "EPOCHS = 10\n",
        "\n",
        "# Train the model\n",
        "multi_step_history = multi_step_model.fit(train_data_multi, epochs=EPOCHS, steps_per_epoch=EVALUATION_INTERVAL,\n",
        "                                          validation_data=val_data_multi, validation_steps=50)\n",
        "\n",
        "# Plot training history\n",
        "plot_train_history(multi_step_history, 'Multi-Step Training and Validation Loss')\n",
        "\n",
        "# Plot some predictions\n",
        "for x, y in val_data_multi.take(5):\n",
        "    plot_time_series([x[0][:, 0].numpy(), y[0].numpy(), multi_step_model.predict(x)], 0, 'LSTM Multi-Step')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mae_lstm_single = multi_step_model.evaluate(val_uni_multi, steps=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZPPGWMAFtjZp"
      },
      "source": [
        "Moving Window Average\n",
        "\n",
        "\n",
        "1.   Given last 20 values of observations(temp) , predict next observation\n",
        "2.   MWA: predict== AVG(last 20 values)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "4MFlF_abinm0"
      },
      "outputs": [],
      "source": [
        "## utility functions\n",
        "\n",
        "## funtion to create data for univariate forecasting\n",
        "\n",
        "def univariate_data(dataset, start_idx , end_idx , history_size, target_size):\n",
        "  data = []\n",
        "  labels = []\n",
        "  start_idx  = start_idx + history_size\n",
        "  if end_idx is None:\n",
        "    end_idx = len(dataset)- target_size\n",
        "  for i in range(start_idx , end_idx):\n",
        "    idxs = range(i-history_size , i)\n",
        "    data.append(np.reshape(dataset[idxs] , (history_size, 1))) ### reshape data\n",
        "    labels.append(dataset[i+target_size])\n",
        "  return np.array(data), np.array(labels)\n",
        "\n",
        "uni_data_history = 20   ## last 50 values\n",
        "uni_data_future = 0     ## future data\n",
        "\n",
        "x_train_uni , y_train_uni = univariate_data(uni_data , 0 , train_split , uni_data_history , uni_data_future)\n",
        "\n",
        "x_val_uni , y_val_uni = univariate_data(uni_data , train_split , None ,uni_data_history , uni_data_future)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train_uni"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "colab_type": "code",
        "id": "61E_3coTin1t",
        "outputId": "3353ffc3-caf2-49d8-f89d-d61773cc1da8"
      },
      "outputs": [],
      "source": [
        "print(x_train_uni.shape , y_train_uni.shape)\n",
        "print(x_val_uni.shape , y_val_uni.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "colab_type": "code",
        "id": "jtbMSRusin70",
        "outputId": "8edffc0a-4a79-4949-d05d-f9de9f0e8e80"
      },
      "outputs": [],
      "source": [
        "print('Single window of history data' , x_train_uni[0])\n",
        "\n",
        "print('Target Temperature to predict ' , y_train_uni[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "colab_type": "code",
        "id": "A411EMdxioEV",
        "outputId": "c9675378-9c3f-498a-c440-d9dc3e54eaef"
      },
      "outputs": [],
      "source": [
        "### fucntion to create time steps\n",
        "def create_time_steps(length):\n",
        "  return list(range(-length,0))\n",
        "\n",
        "### function to plot time series data\n",
        "\n",
        "def plot_time_series(plot_data, delta , title):\n",
        "  labels = [\"History\" , 'True Future' , 'Model Predcited']\n",
        "  marker = ['.-' , 'rx' , 'go']\n",
        "  time_steps = create_time_steps(plot_data[0].shape[0])\n",
        "\n",
        "  if delta:\n",
        "    future = delta\n",
        "  else:\n",
        "    future = 0\n",
        "  plt.title(title)\n",
        "  for i , x in enumerate(plot_data):\n",
        "    if i :\n",
        "      plt.plot(future , plot_data[i] , marker[i], markersize = 10 , label = labels[i])\n",
        "    else:\n",
        "      plt.plot(time_steps, plot_data[i].flatten(), marker[i], label = labels[i])\n",
        "  plt.legend()\n",
        "  plt.xlim([time_steps[0], (future+5) *2])\n",
        "\n",
        "  plt.xlabel('Time_Step')\n",
        "  return plt\n",
        "## function to plot time series data\n",
        "\n",
        "\n",
        "\n",
        "plot_time_series([x_train_uni[0] , y_train_uni[0]] , 0 , 'Sample Example')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "colab_type": "code",
        "id": "b5X3X05xioK0",
        "outputId": "d4442f52-0016-4061-d113-c9223ddff459"
      },
      "outputs": [],
      "source": [
        "i = 20\n",
        "plot_time_series([x_train_uni[i], y_train_uni[i]] , 0 , 'Sample Example')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "NiL0a-R5ioSI"
      },
      "outputs": [],
      "source": [
        "### Moving window average\n",
        "\n",
        "def MWA(history):\n",
        "  return np.mean(history)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "colab_type": "code",
        "id": "5O6tADOmioZ8",
        "outputId": "b064d6ce-87de-47ee-d48c-56565accba1d"
      },
      "outputs": [],
      "source": [
        "i = 20\n",
        "plot_time_series([x_train_uni[i] , y_train_uni[i] , MWA(x_train_uni[i])] , 0 , 'MWA predicted')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oc-bXND--IuJ"
      },
      "source": [
        "Univariate time-series forecasting\n",
        "\n",
        "\n",
        "*   Only single feature as temperature(historical data)\n",
        "*   Task:  Given last 20 observations(history) , predict next temperature value \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "colab_type": "code",
        "id": "zPd4HuN-ior8",
        "outputId": "739b28f3-18c7-4db0-efce-447de9a5b884"
      },
      "outputs": [],
      "source": [
        "## prepare tensorflow dataset\n",
        "batch_size = 256\n",
        "buffer_size = 10000\n",
        "\n",
        "train_uni = tf.data.Dataset.from_tensor_slices((x_train_uni , y_train_uni))\n",
        "train_uni = train_uni.cache().shuffle(buffer_size).batch(batch_size).repeat()\n",
        "\n",
        "val_uni = tf.data.Dataset.from_tensor_slices((x_val_uni , y_val_uni))\n",
        "val_uni = val_uni.cache().shuffle(buffer_size).batch(batch_size).repeat()\n",
        "\n",
        "print(train_uni)\n",
        "print(val_uni)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "colab_type": "code",
        "id": "uB-3VgOJioyT",
        "outputId": "51383501-4165-4bd6-800f-b47269e8d88e"
      },
      "outputs": [],
      "source": [
        "## Define LSTM model \n",
        "\n",
        "lstm_model = tf.keras.models.Sequential([tf.keras.layers.LSTM(8 , input_shape = x_train_uni.shape[-2:]), \n",
        "                                         tf.keras.layers.Dense(1)])\n",
        "\n",
        "lstm_model.compile(optimizer = 'adam', loss = 'mae')\n",
        "\n",
        "steps = 200\n",
        "\n",
        "EPOCHS =10\n",
        "\n",
        "lstm_model.fit(train_uni , epochs = EPOCHS, steps_per_epoch = steps ,\n",
        "               validation_data = val_uni, validation_steps = 50)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "colab_type": "code",
        "id": "DKEA53lliov0",
        "outputId": "fb4cf444-7200-4992-9758-fa70c0043598"
      },
      "outputs": [],
      "source": [
        "for i , j in val_uni.take(5):\n",
        "  plot = plot_time_series([i[0].numpy() , j[0].numpy() , lstm_model.predict(i)[0]] ,0 , 'LSTM UNIVARIATE')\n",
        "  plot.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MTfs6GPbDOiL"
      },
      "source": [
        "Multivariate  and Single step Forecasting\n",
        "\n",
        "\n",
        "*   Task: Given 3 features(temp , pressure , and density) at each time step can we predict the temp in future at single time step\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "colab_type": "code",
        "id": "Hh2HnNjxiopi",
        "outputId": "a56dd85c-86c9-4e8a-aa7c-892eb4b342d1"
      },
      "outputs": [],
      "source": [
        "## features \n",
        "\n",
        "# features_6 = ['temperature', 'humidity', 'pressure', 'global_irradiance', 'direct_irradiance', 'diffuse_irradiance']\n",
        "features14 = [\n",
        "    'temperature', 'humidity', 'pressure',\n",
        "    'cloud_cover', 'wind_speed', 'wind_direction', 'poprecipitation'\n",
        "]\n",
        "features = df[features14]\n",
        "features.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "features.isnull().sum()\n",
        "features=features.fillna(features.mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475
        },
        "colab_type": "code",
        "id": "Uaz4LXuUioiq",
        "outputId": "2ed6f021-f8e5-43a0-b301-21be42024f6d"
      },
      "outputs": [],
      "source": [
        "features.plot(subplots=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "n5Ft3nfyiogy"
      },
      "outputs": [],
      "source": [
        "# ### standardize data\n",
        "dataset = features.values\n",
        "# dataset = np.array(features)\n",
        "data_mean = dataset[:train_split].mean(axis =0)\n",
        "\n",
        "data_std = dataset[:train_split].std(axis = 0)\n",
        "\n",
        "dataset = (dataset - data_mean)/data_std\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "i4LP5gdAiocw"
      },
      "outputs": [],
      "source": [
        "# # ### create mutlivariate data\n",
        "\n",
        "# def multivariate_data(dataset, target, start_idx, end_idx, history_size, target_size, step, single_step=False):\n",
        "#     data, labels = [], []\n",
        "#     start_idx += history_size\n",
        "#     if end_idx is None:\n",
        "#         end_idx = len(dataset) - target_size\n",
        "#     for i in range(start_idx, end_idx):\n",
        "#         indices = range(i-history_size, i, step)\n",
        "#         data.append(dataset[indices])\n",
        "#         if single_step:\n",
        "#             labels.append(target[i+target_size])\n",
        "#         else:\n",
        "#             labels.append(target[i:i+target_size])\n",
        "#     return np.array(data), np.array(labels)\n",
        "def multivariate_data(dataset, target, start_index, end_index, history_size,\n",
        "                      target_size, step, single_step=False):\n",
        "    data = []\n",
        "    labels = []\n",
        "\n",
        "    # Adjust end_index to avoid out-of-bounds error\n",
        "    end_index = end_index if end_index is not None else len(dataset) - target_size\n",
        "    \n",
        "    # Adjust start_index to accommodate history_size\n",
        "    start_index = start_index + history_size\n",
        "\n",
        "    for i in range(start_index, end_index):\n",
        "        indices = range(i-history_size, i, step)\n",
        "        data.append(dataset[indices])\n",
        "\n",
        "        if single_step:\n",
        "            labels.append(target[i+target_size])\n",
        "        else:\n",
        "            labels.append(target[i:i+target_size])\n",
        "    \n",
        "    return np.array(data), np.array(labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "qmdeBNcuioYX",
        "outputId": "d6f3a6a9-ff5b-4b45-8eeb-35a96b06293a"
      },
      "outputs": [],
      "source": [
        "# ### generate multivariate data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# history = 720\n",
        "# future_target = 72\n",
        "# STEP = 6\n",
        "\n",
        "# x_train_ss, y_train_ss = multivariate_data(dataset, dataset[:, 1], 0, train_split, history,\n",
        "#                                            future_target, STEP, single_step=True)\n",
        "\n",
        "\n",
        "# x_val_ss , y_val_ss = multivariate_data(dataset , dataset[:,1] , train_split , None , history,\n",
        "#                                         future_target, STEP, single_step = True)\n",
        "\n",
        "\n",
        "# print(x_train_ss.shape , y_train_ss.shape)\n",
        "# Define your parameters\n",
        "# Define your parameters\n",
        "history = 720\n",
        "future_target = 72\n",
        "STEP = 6\n",
        "train_split = int(len(dataset) * 0.7)\n",
        "# scaler = StandardScaler()\n",
        "# scaler.fit(dataset[:train_split])\n",
        "\n",
        "# # Transform the entire dataset\n",
        "# dataset = scaler.transform(dataset)\n",
        "# Get training data\n",
        "x_train_ss, y_train_ss = multivariate_data(dataset, dataset[:, 1], 0, train_split, history, future_target, STEP, single_step=True)\n",
        "\n",
        "# Get validation data\n",
        "x_val_ss, y_val_ss = multivariate_data(dataset, dataset[:, 1], train_split, None, history, future_target, STEP, single_step=True)\n",
        "\n",
        "# Check shapes\n",
        "print(x_train_ss.shape, y_train_ss.shape)\n",
        "print(x_val_ss.shape, y_val_ss.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train_ss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "colab_type": "code",
        "id": "Ufyzs-nFioVO",
        "outputId": "246c3cbd-082b-4345-efbc-7863582bb575"
      },
      "outputs": [],
      "source": [
        "## tensorflow dataset\n",
        "\n",
        "train_ss = tf.data.Dataset.from_tensor_slices((x_train_ss, y_train_ss))\n",
        "train_ss = train_ss.cache().shuffle(buffer_size).batch(batch_size).repeat()\n",
        "\n",
        "val_ss = tf.data.Dataset.from_tensor_slices((x_val_ss, y_val_ss))\n",
        "val_ss = val_ss.cache().shuffle(buffer_size).batch(batch_size).repeat()\n",
        "\n",
        "print(train_ss)\n",
        "print(val_ss)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "colab_type": "code",
        "id": "Rb2wsAl_ioQ5",
        "outputId": "f3e45add-1257-406c-d926-824837951a7e"
      },
      "outputs": [],
      "source": [
        "### Modelling using LSTM\n",
        "from keras.callbacks import EarlyStopping\n",
        "callbacks = EarlyStopping(\n",
        "    patience = 10 , \n",
        "    restore_best_weights = True , \n",
        "    monitor = 'val_loss'\n",
        ")\n",
        "single_step_model = tf.keras.models.Sequential()\n",
        "\n",
        "single_step_model.add(tf.keras.layers.LSTM(16, return_sequences=True,input_shape = x_train_ss.shape[-2:]))\n",
        "# single_step_model.add(tf.keras.layers.LSTM(16,return_sequences=False))\n",
        "# single_step_model.add(tf.keras.layers.Dense(4, activation=\"relu\"))\n",
        "single_step_model.add(tf.keras.layers.Dense(1))\n",
        "single_step_model.compile(optimizer = tf.keras.optimizers.Adam(clipvalue=1.0,weight_decay=1e-6), loss = 'mae')\n",
        "single_step_model.summary()\n",
        "\n",
        "\n",
        "single_step_model_history = single_step_model.fit(train_ss, epochs = EPOCHS ,\n",
        "                                                  steps_per_epoch =steps,verbose=1, validation_data = val_ss,\n",
        "                                                  validation_steps = 50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "colab_type": "code",
        "id": "6-z4nTiFioND",
        "outputId": "c79a043e-97bc-4662-a842-069fdbbb432c"
      },
      "outputs": [],
      "source": [
        "## plot train test loss \n",
        "\n",
        "def plot_loss(history , title):\n",
        "  loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss']\n",
        "\n",
        "  epochs = range(len(loss))\n",
        "  plt.figure()\n",
        "  plt.plot(epochs, loss , 'b' , label = 'Train Loss')\n",
        "  plt.plot(epochs, val_loss , 'r' , label = 'Validation Loss')\n",
        "  plt.title(title)\n",
        "  plt.legend()\n",
        "  plt.grid()\n",
        "  plt.show()\n",
        "\n",
        "plot_loss(single_step_model_history , 'Single Step Training and validation loss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "colab_type": "code",
        "id": "b2lNfZZLioJG",
        "outputId": "b9ab67ae-4941-4ae1-a589-baa8bffebd18"
      },
      "outputs": [],
      "source": [
        "# plot time series and predicted values\n",
        "\n",
        "for x, y in val_ss.take(5):\n",
        "  plot = plot_time_series([x[0][:, 1].numpy(), y[0].numpy(),\n",
        "                    single_step_model.predict(x)[0]], 12,\n",
        "                   'Single Step Prediction')\n",
        "  plot.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "D9Kz451TRYtL"
      },
      "source": [
        "Multi-variate & multi-step forecasting\n",
        "-> Generate multiple future values of temperature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "colab_type": "code",
        "id": "c9g7pWStioAV",
        "outputId": "de2d7375-4614-4369-c8a7-0469bf395648"
      },
      "outputs": [],
      "source": [
        "future_target = 72 # 72 future values\n",
        "x_train_multi, y_train_multi = multivariate_data(dataset, dataset[:, 1], 0,\n",
        "                                                 train_split, history,\n",
        "                                                 future_target, STEP)\n",
        "x_val_multi, y_val_multi = multivariate_data(dataset, dataset[:, 1],\n",
        "                                             train_split, None, history,\n",
        "                                             future_target, STEP)\n",
        "\n",
        "print(x_train_multi.shape)\n",
        "print(y_train_multi.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Fkwcf3UNin6l"
      },
      "outputs": [],
      "source": [
        "# TF DATASET\n",
        "\n",
        "train_data_multi = tf.data.Dataset.from_tensor_slices((x_train_multi, y_train_multi))\n",
        "train_data_multi = train_data_multi.cache().shuffle(buffer_size).batch(batch_size).repeat()\n",
        "\n",
        "val_data_multi = tf.data.Dataset.from_tensor_slices((x_val_multi, y_val_multi))\n",
        "val_data_multi = val_data_multi.batch(batch_size).repeat()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "colab_type": "code",
        "id": "GPyypB20in0P",
        "outputId": "8dff268f-7ca0-4881-f4ee-704cd053f81e"
      },
      "outputs": [],
      "source": [
        "#plotting function\n",
        "def multi_step_plot(history, true_future, prediction):\n",
        "  plt.figure(figsize=(12, 6))\n",
        "  num_in = create_time_steps(len(history))\n",
        "  num_out = len(true_future)\n",
        "  plt.grid()\n",
        "  plt.plot(num_in, np.array(history[:, 1]), label='History')\n",
        "  plt.plot(np.arange(num_out)/STEP, np.array(true_future), 'bo',\n",
        "           label='True Future')\n",
        "  if prediction.any():\n",
        "    plt.plot(np.arange(num_out)/STEP, np.array(prediction), 'ro',\n",
        "             label='Predicted Future')\n",
        "  plt.legend(loc='upper left')\n",
        "  plt.show()\n",
        "  \n",
        "\n",
        "\n",
        "for x, y in train_data_multi.take(1):\n",
        "  multi_step_plot(x[0], y[0], np.array([0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "colab_type": "code",
        "id": "28MmEpt8TD12",
        "outputId": "5cd8459f-2c71-4856-8326-1e22ec4f8fa4"
      },
      "outputs": [],
      "source": [
        "# multi_step_model = tf.keras.models.Sequential()\n",
        "# multi_step_model.add(tf.keras.layers.LSTM(16,\n",
        "#                                           return_sequences=True,\n",
        "#                                           input_shape=x_train_multi.shape[-2:]))\n",
        "# multi_step_model.add(tf.keras.layers.LSTM(32,return_sequences=False, activation='relu'))\n",
        "# multi_step_model.add(tf.keras.layers.Dense(4))\n",
        "# multi_step_model.add(tf.keras.layers.Dense(72)) # for 72 outputs\n",
        "\n",
        "# multi_step_model.compile(optimizer=tf.keras.optimizers.SGD(clipvalue=1.0,weight_decay=1e-6), loss='mae')\n",
        "# multi_step_model.summary()\n",
        "# multi_step_history = multi_step_model.fit(train_data_multi, epochs=EPOCHS,\n",
        "#                                           steps_per_epoch=steps,\n",
        "#                                           validation_data=val_data_multi,\n",
        "#                                           validation_steps=50,callbacks = [callbacks])\n",
        "\n",
        "\n",
        "\n",
        "# Define the model\n",
        "multi_step_model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.LSTM(64, return_sequences=True, input_shape=x_train_multi.shape[-2:]),\n",
        "    # tf.keras.layers.Dropout(0.2),  # Dropout layer for regularization\n",
        "    tf.keras.layers.LSTM(16, return_sequences=False, activation='relu'),\n",
        "    # tf.keras.layers.Dropout(0.2),  # Dropout layer for regularization\n",
        "    # tf.keras.layers.LSTM(2, return_sequences=False, activation='relu'),\n",
        "    tf.keras.layers.Dense(4, activation='relu'),  # Additional dense layer\n",
        "    tf.keras.layers.Dense(72)  # 72 outputs for future predictions\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "multi_step_model.compile(optimizer=tf.keras.optimizers.Adam(clipvalue=1.0,weight_decay=1e-6), loss='mae')\n",
        "\n",
        "# Print the model summary\n",
        "multi_step_model.summary()\n",
        "\n",
        "# Define callbacks for early stopping and learning rate scheduling\n",
        "# \n",
        "\n",
        "# Fit the model\n",
        "enhanced_history = multi_step_model.fit(train_data_multi, \n",
        "                                      epochs=EPOCHS,\n",
        "                                      steps_per_epoch=steps,\n",
        "                                      validation_data=val_data_multi,\n",
        "                                      validation_steps=50\n",
        "                                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "colab_type": "code",
        "id": "zaCJerqLinvP",
        "outputId": "266d7736-69ed-4dc6-f46a-f025417209f0"
      },
      "outputs": [],
      "source": [
        "plot_loss(enhanced_history, 'Multi-Step Training and validation loss')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "colab_type": "code",
        "id": "9ohuOxLrinkt",
        "outputId": "df84339c-c680-49e0-d80e-def97e196e87"
      },
      "outputs": [],
      "source": [
        "for x, y in val_data_multi.take(5):\n",
        "  multi_step_plot(x[0], y[0], multi_step_model.predict(x)[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mae_lstm_single = single_step_model.evaluate(val_ss, steps=100)\n",
        "mae_lstm_multi=multi_step_model.evaluate(val_data_multi, steps=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the model\n",
        "loaded_model = load_model('/Users/faymajidelhassan/Downloads/Master project /CODE/EDA/Saved_models/Lstm_multi_step_model_measure+precip.h5')\n",
        "loaded_model2 = load_model('/Users/faymajidelhassan/Downloads/Master project /CODE/EDA/Saved_models/Lstm_single_step_model_measure+precip.h5')\n",
        "\n",
        "# Optionally, you can verify the model by making predictions\n",
        "for x, y in val_data_multi.take(5):\n",
        "\n",
        "    predictions = loaded_model.predict(x)\n",
        "    multi_step_plot(x[0], y[0], loaded_model.predict(x)[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.losses import MeanAbsoluteError\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define a dictionary with custom objects if needed\n",
        "custom_objects = {'mae': MeanAbsoluteError()}\n",
        "\n",
        "# Load the models\n",
        "loaded_model = load_model('/Users/faymajidelhassan/Downloads/Master project /CODE/EDA/Saved_models/Lstm_multi_step_model_measure+precip.h5', custom_objects=custom_objects)\n",
        "loaded_model2 = load_model('/Users/faymajidelhassan/Downloads/Master project /CODE/EDA/Saved_models/Lstm_single_step_model_measure+precip.h5', custom_objects=custom_objects)\n",
        "\n",
        "print(\"Models loaded successfully\")\n",
        "\n",
        "# Define the multi-step plot function\n",
        "def multi_step_plot(history, true_future, prediction):\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    num_in = list(range(-len(history), 0))\n",
        "    num_out = list(range(len(true_future)))\n",
        "\n",
        "    plt.plot(num_in, np.array(history[:, 1]), label='History')\n",
        "    plt.plot(num_out, np.array(true_future), 'bo-', label='True Future')  # Change 'bo' to 'bo-' to plot line with markers\n",
        "    plt.plot(num_out, np.array(prediction), 'ro-', label='Predicted Future')  # Change 'ro' to 'ro-' to plot line with markers\n",
        "\n",
        "    plt.legend(loc='upper left')\n",
        "    plt.xlabel('Time Steps')\n",
        "    plt.ylabel('Value')\n",
        "    plt.title('Multi-Step Forecasting')\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "# Use the loaded model to make predictions and plot them\n",
        "for x, y in val_data_multi.take(5):\n",
        "    prediction = loaded_model.predict(x)[0]\n",
        "    multi_step_plot(x[0], y[0], prediction)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mae_lstm_multi=loaded_model.evaluate(val_data_multi, steps=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "mR8GfISvineh"
      },
      "outputs": [],
      "source": [
        "for x, y in val_ss.take(5):\n",
        "    prediction = transformer_model.predict(x)\n",
        "    plot = plot_time_series([x[0].numpy(), y[0].numpy(), prediction[0]], 'Transformer UNIVARIATE')\n",
        "    plot.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Fghz0HC4inWu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "mVJZCCyEinR6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "XwU_HaVDinNz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "pmUq6V7rinHc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "nWdiY-THinCH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "oMyZ_5Zyim7-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Qc3pxLPBim4k"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "w8y2R6zVim0X"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "cR1L9pvfimt4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Time Series Forecasting (Predicting Temperature) using LSTM .ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
